{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a10f3a3",
   "metadata": {},
   "source": [
    "# Legal Document Role Classifier Training Notebook\n",
    "\n",
    "This notebook provides a comprehensive guide to train your own rhetorical role classifier for legal documents using your existing dataset.\n",
    "\n",
    "## Dataset Structure\n",
    "Your data should be in the format:\n",
    "```\n",
    "sentence1\\trole1\n",
    "sentence2\\trole2\n",
    "\\n\n",
    "sentence1\\trole1  # New document\n",
    "sentence2\\trole2\n",
    "```\n",
    "\n",
    "## Supported Roles\n",
    "- Facts\n",
    "- Issue\n",
    "- Arguments of Petitioner\n",
    "- Arguments of Respondent\n",
    "- Reasoning\n",
    "- Decision\n",
    "- None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7e628df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./server/.venv/lib/python3.12/site-packages (2.8.0)\n",
      "Requirement already satisfied: transformers in ./server/.venv/lib/python3.12/site-packages (4.55.4)\n",
      "Requirement already satisfied: scikit-learn in ./server/.venv/lib/python3.12/site-packages (1.7.1)\n",
      "Requirement already satisfied: pandas in ./server/.venv/lib/python3.12/site-packages (2.3.2)\n",
      "Requirement already satisfied: matplotlib in ./server/.venv/lib/python3.12/site-packages (3.10.5)\n",
      "Requirement already satisfied: seaborn in ./server/.venv/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: spacy in ./server/.venv/lib/python3.12/site-packages (3.8.7)\n",
      "Requirement already satisfied: filelock in ./server/.venv/lib/python3.12/site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./server/.venv/lib/python3.12/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in ./server/.venv/lib/python3.12/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./server/.venv/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in ./server/.venv/lib/python3.12/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in ./server/.venv/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in ./server/.venv/lib/python3.12/site-packages (from torch) (2025.7.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in ./server/.venv/lib/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in ./server/.venv/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in ./server/.venv/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in ./server/.venv/lib/python3.12/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in ./server/.venv/lib/python3.12/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in ./server/.venv/lib/python3.12/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in ./server/.venv/lib/python3.12/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./server/.venv/lib/python3.12/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./server/.venv/lib/python3.12/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./server/.venv/lib/python3.12/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in ./server/.venv/lib/python3.12/site-packages (from torch) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./server/.venv/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./server/.venv/lib/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./server/.venv/lib/python3.12/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in ./server/.venv/lib/python3.12/site-packages (from torch) (3.4.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in ./server/.venv/lib/python3.12/site-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: numpy>=1.17 in ./server/.venv/lib/python3.12/site-packages (from transformers) (2.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in ./server/.venv/lib/python3.12/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./server/.venv/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./server/.venv/lib/python3.12/site-packages (from transformers) (2025.7.34)\n",
      "Requirement already satisfied: requests in ./server/.venv/lib/python3.12/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./server/.venv/lib/python3.12/site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./server/.venv/lib/python3.12/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./server/.venv/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./server/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.8)\n",
      "Requirement already satisfied: scipy>=1.8.0 in ./server/.venv/lib/python3.12/site-packages (from scikit-learn) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./server/.venv/lib/python3.12/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./server/.venv/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./server/.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./server/.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./server/.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./server/.venv/lib/python3.12/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./server/.venv/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./server/.venv/lib/python3.12/site-packages (from matplotlib) (4.59.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./server/.venv/lib/python3.12/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in ./server/.venv/lib/python3.12/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./server/.venv/lib/python3.12/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in ./server/.venv/lib/python3.12/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./server/.venv/lib/python3.12/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./server/.venv/lib/python3.12/site-packages (from spacy) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./server/.venv/lib/python3.12/site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./server/.venv/lib/python3.12/site-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in ./server/.venv/lib/python3.12/site-packages (from spacy) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in ./server/.venv/lib/python3.12/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in ./server/.venv/lib/python3.12/site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./server/.venv/lib/python3.12/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in ./server/.venv/lib/python3.12/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in ./server/.venv/lib/python3.12/site-packages (from spacy) (0.16.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in ./server/.venv/lib/python3.12/site-packages (from spacy) (2.11.7)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./server/.venv/lib/python3.12/site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in ./server/.venv/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./server/.venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./server/.venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./server/.venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./server/.venv/lib/python3.12/site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./server/.venv/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./server/.venv/lib/python3.12/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./server/.venv/lib/python3.12/site-packages (from requests->transformers) (2025.8.3)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in ./server/.venv/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in ./server/.venv/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in ./server/.venv/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./server/.venv/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in ./server/.venv/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (14.1.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in ./server/.venv/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in ./server/.venv/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.0.post1)\n",
      "Requirement already satisfied: wrapt in ./server/.venv/lib/python3.12/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.3)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in ./server/.venv/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in ./server/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./server/.venv/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./server/.venv/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./server/.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./server/.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./server/.venv/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# Install required packages if needed\n",
    "!pip install torch transformers scikit-learn pandas matplotlib seaborn spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf95d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /home/nyaya/server\n",
      "PyTorch version: 2.8.0+cu128\n",
      "CUDA available: True\n",
      "CUDA device: Quadro RTX 6000\n"
     ]
    }
   ],
   "source": [
    "# Setup and imports\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add your project path - Using relative path for portability\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "PROJECT_ROOT = NOTEBOOK_DIR / \"server\"\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "sys.path.append(str(PROJECT_ROOT / \"src\" / \"models\" / \"training\"))\n",
    "\n",
    "print(f\"Notebook directory: {NOTEBOOK_DIR}\")\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9f7672a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Import error: No module named 'tensorboard'\n",
      "Please ensure you're running from the correct directory\n"
     ]
    }
   ],
   "source": [
    "# Import training modules\n",
    "try:\n",
    "    from train import RoleClassifierTrainer\n",
    "    from data_loader import create_data_loaders, LegalDocumentDataset\n",
    "    from evaluate import ModelEvaluator\n",
    "    from src.models.role_classifier import RoleClassifier, RhetoricalRole\n",
    "    print(\"‚úÖ Successfully imported training modules\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Import error: {e}\")\n",
    "    print(\"Please ensure you're running from the correct directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7859ed69",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3768e114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  train_data: /home/nyaya/server/dataset/Hier_BiLSTM_CRF/train\n",
      "  val_data: /home/nyaya/server/dataset/Hier_BiLSTM_CRF/val\n",
      "  test_data: /home/nyaya/server/dataset/Hier_BiLSTM_CRF/test\n",
      "  model_type: inlegalbert\n",
      "  model_name: law-ai/InLegalBERT\n",
      "  context_mode: prev\n",
      "  batch_size: 16\n",
      "  num_epochs: 10\n",
      "  learning_rate: 2e-05\n",
      "  weight_decay: 0.01\n",
      "  max_length: 512\n",
      "  warmup_steps: 500\n",
      "  device: cuda\n",
      "  output_dir: ./trained_models\n",
      "  save_best_model: True\n"
     ]
    }
   ],
   "source": [
    "# Training Configuration\n",
    "config = {\n",
    "    # Data paths - Using relative paths for portability\n",
    "    \"train_data\": str(PROJECT_ROOT / \"dataset\" / \"Hier_BiLSTM_CRF\" / \"train\"),\n",
    "    \"val_data\": str(PROJECT_ROOT / \"dataset\" / \"Hier_BiLSTM_CRF\" / \"val\"),\n",
    "    \"test_data\": str(PROJECT_ROOT / \"dataset\" / \"Hier_BiLSTM_CRF\" / \"test\"),\n",
    "    \n",
    "    # Model configuration\n",
    "    \"model_type\": \"inlegalbert\",  # Options: \"inlegalbert\", \"bilstm_crf\"\n",
    "    \"model_name\": \"law-ai/InLegalBERT\",  # Pre-trained model\n",
    "    \"context_mode\": \"prev\",  # Options: \"single\", \"prev\", \"prev_two\", \"surrounding\"\n",
    "    \n",
    "    # Training hyperparameters\n",
    "    \"batch_size\": 16,\n",
    "    \"num_epochs\": 5,\n",
    "    \"learning_rate\": 2e-5,\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"max_length\": 512,\n",
    "    \"warmup_steps\": 500,\n",
    "    \n",
    "    # Class imbalance handling\n",
    "    \"use_class_weights\": True,  # IMPORTANT: Handle \"None\" label dominance\n",
    "    \"class_weight_method\": \"inverse_freq\",  # Options: \"inverse_freq\", \"balanced\", \"manual\"\n",
    "    \n",
    "    # Device and output\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"output_dir\": \"./trained_models\",\n",
    "    \"save_best_model\": True\n",
    "}\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for key, value in config.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è  Class Imbalance Handling: ENABLED\")\n",
    "print(\"   ‚Üí This will prevent the model from over-predicting 'None'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a183d51",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è Handling Class Imbalance\n",
    "\n",
    "**Problem**: The \"None\" label often dominates the dataset, which can cause the model to:\n",
    "- Predict \"None\" too frequently\n",
    "- Ignore minority classes (Issue, Decision, etc.)\n",
    "- Achieve high accuracy but poor per-class performance\n",
    "\n",
    "**Solutions Implemented**:\n",
    "1. **Class Weights**: Give higher importance to minority classes during training\n",
    "2. **Focal Loss**: Focus on hard-to-classify examples\n",
    "3. **Data Filtering**: Option to reduce \"None\" samples\n",
    "4. **Balanced Sampling**: Sample from each class equally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2affb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze class distribution to understand the imbalance\n",
    "def analyze_class_distribution(data_path, sample_size=50):\n",
    "    \"\"\"Analyze label distribution across dataset\"\"\"\n",
    "    data_path = Path(data_path)\n",
    "    files = list(data_path.glob(\"*.txt\"))[:sample_size]\n",
    "    \n",
    "    all_labels = []\n",
    "    \n",
    "    for file_path in files:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if line and '\\t' in line:\n",
    "                    parts = line.split('\\t')\n",
    "                    if len(parts) >= 2:\n",
    "                        label = parts[1].strip()\n",
    "                        all_labels.append(label)\n",
    "    \n",
    "    # Count labels\n",
    "    from collections import Counter\n",
    "    label_counts = Counter(all_labels)\n",
    "    total = len(all_labels)\n",
    "    \n",
    "    print(f\"üìä Class Distribution Analysis (from {len(files)} files):\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"{'Label':<30} {'Count':>10} {'Percentage':>12} {'Imbalance Ratio':>15}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    max_count = max(label_counts.values())\n",
    "    \n",
    "    for label, count in sorted(label_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "        percentage = (count / total) * 100\n",
    "        imbalance_ratio = max_count / count\n",
    "        print(f\"{label:<30} {count:>10,} {percentage:>11.2f}% {imbalance_ratio:>14.1f}x\")\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Total sentences: {total:,}\")\n",
    "    \n",
    "    # Calculate class weights for handling imbalance\n",
    "    class_weights = {}\n",
    "    for label, count in label_counts.items():\n",
    "        weight = total / (len(label_counts) * count)\n",
    "        class_weights[label] = weight\n",
    "    \n",
    "    print(f\"\\nüí° Recommended Class Weights (to balance training):\")\n",
    "    for label, weight in sorted(class_weights.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"  {label:<30} ‚Üí {weight:.3f}\")\n",
    "    \n",
    "    return label_counts, class_weights\n",
    "\n",
    "# Analyze training data\n",
    "print(\"üîç Analyzing Training Data Distribution...\\n\")\n",
    "label_counts, class_weights = analyze_class_distribution(config[\"train_data\"], sample_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e5d7ee",
   "metadata": {},
   "source": [
    "### Strategy Selection\n",
    "\n",
    "Based on the imbalance severity, choose one or more strategies:\n",
    "\n",
    "1. **Mild Imbalance (2-5x)**: Use class weights only\n",
    "2. **Moderate Imbalance (5-20x)**: Use class weights + focal loss\n",
    "3. **Severe Imbalance (>20x)**: Consider filtering \"None\" samples or undersampling\n",
    "\n",
    "**Current Configuration**: The notebook will use **class weights** by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6114335f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure imbalance handling strategies\n",
    "imbalance_config = {\n",
    "    # Strategy 1: Use class weights (RECOMMENDED - Always use this)\n",
    "    \"use_class_weights\": True,\n",
    "    \n",
    "    # Strategy 2: Filter excessive \"None\" samples (Optional - for severe imbalance)\n",
    "    \"filter_none_samples\": False,  # Set to True if \"None\" > 50% of dataset\n",
    "    \"none_keep_ratio\": 0.3,  # Keep only 30% of \"None\" samples if filtering\n",
    "    \n",
    "    # Strategy 3: Focal loss parameters (Optional - for hard examples)\n",
    "    \"use_focal_loss\": False,  # Set to True for severe imbalance\n",
    "    \"focal_alpha\": 0.25,  # Balance between positive/negative\n",
    "    \"focal_gamma\": 2.0,   # Focus on hard examples\n",
    "    \n",
    "    # Strategy 4: Oversampling minority classes (Optional)\n",
    "    \"oversample_minority\": False,  # Duplicate rare class samples\n",
    "    \"target_balance_ratio\": 5.0,  # Max imbalance ratio after balancing\n",
    "}\n",
    "\n",
    "print(\"‚öôÔ∏è Imbalance Handling Configuration:\")\n",
    "print(\"=\" * 60)\n",
    "for key, value in imbalance_config.items():\n",
    "    print(f\"  {key:<25} ‚Üí {value}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if imbalance_config[\"use_class_weights\"]:\n",
    "    print(\"\\n‚úÖ Class weights will be applied during training\")\n",
    "    print(\"   ‚Üí Minority classes will have higher importance in loss\")\n",
    "\n",
    "if imbalance_config[\"filter_none_samples\"]:\n",
    "    print(\"\\n‚úÖ 'None' samples will be reduced\")\n",
    "    print(f\"   ‚Üí Keeping {imbalance_config['none_keep_ratio']*100:.0f}% of 'None' samples\")\n",
    "\n",
    "if imbalance_config[\"use_focal_loss\"]:\n",
    "    print(\"\\n‚úÖ Focal loss will be used\")\n",
    "    print(\"   ‚Üí Model will focus on hard-to-classify examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d892bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class imbalance and weights\n",
    "if 'label_counts' in locals() and 'class_weights' in locals():\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Plot 1: Class distribution (shows imbalance problem)\n",
    "    labels = list(label_counts.keys())\n",
    "    counts = list(label_counts.values())\n",
    "    colors = ['red' if label == 'None' else 'skyblue' for label in labels]\n",
    "    \n",
    "    ax1.bar(labels, counts, color=colors, alpha=0.7)\n",
    "    ax1.set_title('‚ö†Ô∏è Class Imbalance Problem\\n(\"None\" dominates)', fontsize=14, fontweight='bold')\n",
    "    ax1.set_xlabel('Rhetorical Role', fontsize=12)\n",
    "    ax1.set_ylabel('Number of Samples', fontsize=12)\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Add count labels\n",
    "    for i, (label, count) in enumerate(zip(labels, counts)):\n",
    "        ax1.text(i, count + max(counts)*0.01, f'{count:,}', ha='center', va='bottom')\n",
    "    \n",
    "    # Plot 2: Class weights (shows solution)\n",
    "    weight_labels = list(class_weights.keys())\n",
    "    weight_values = list(class_weights.values())\n",
    "    colors2 = ['green' if w > 1.0 else 'orange' for w in weight_values]\n",
    "    \n",
    "    ax2.bar(weight_labels, weight_values, color=colors2, alpha=0.7)\n",
    "    ax2.set_title('‚úÖ Class Weights Solution\\n(Higher weights = More importance)', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel('Rhetorical Role', fontsize=12)\n",
    "    ax2.set_ylabel('Weight Multiplier', fontsize=12)\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "    ax2.axhline(y=1.0, color='black', linestyle='--', alpha=0.3, label='Baseline (1.0)')\n",
    "    \n",
    "    # Add weight labels\n",
    "    for i, (label, weight) in enumerate(zip(weight_labels, weight_values)):\n",
    "        ax2.text(i, weight + max(weight_values)*0.01, f'{weight:.2f}x', ha='center', va='bottom')\n",
    "    \n",
    "    ax2.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüí° Interpretation:\")\n",
    "    print(\"  LEFT: Raw data shows severe imbalance (None dominates)\")\n",
    "    print(\"  RIGHT: Class weights compensate by giving minority classes higher importance\")\n",
    "    print(\"         ‚Üí Rare classes get amplified during training loss calculation\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Run the class distribution analysis cell first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fa8e91",
   "metadata": {},
   "source": [
    "### üìö Practical Strategies to Handle \"None\" Dominance\n",
    "\n",
    "#### **Strategy 1: Class Weights (RECOMMENDED - Already Enabled)**\n",
    "‚úÖ **What it does**: Multiplies the loss for each class inversely proportional to its frequency\n",
    "- \"None\" (abundant) ‚Üí Low weight (e.g., 0.2x)\n",
    "- \"Issue\" (rare) ‚Üí High weight (e.g., 5.0x)\n",
    "\n",
    "‚úÖ **Pros**: \n",
    "- Easy to implement\n",
    "- No data loss\n",
    "- Works well for moderate imbalance\n",
    "\n",
    "‚ùå **Cons**: May not fully solve severe imbalance (>50x ratio)\n",
    "\n",
    "---\n",
    "\n",
    "#### **Strategy 2: Filter \"None\" Samples**\n",
    "What it does: Randomly discard some \"None\" samples to balance the dataset\n",
    "\n",
    "```python\n",
    "# Example: Keep only 30% of \"None\" samples\n",
    "imbalance_config[\"filter_none_samples\"] = True\n",
    "imbalance_config[\"none_keep_ratio\"] = 0.3\n",
    "```\n",
    "\n",
    "‚úÖ **Pros**: Directly balances the dataset\n",
    "‚ùå **Cons**: Loses potentially useful data\n",
    "\n",
    "---\n",
    "\n",
    "#### **Strategy 3: Stratified Sampling**\n",
    "What it does: Ensure each batch has balanced representation of all classes\n",
    "\n",
    "‚úÖ **Pros**: Guarantees balanced learning in each batch\n",
    "‚ùå **Cons**: Requires custom data loader\n",
    "\n",
    "---\n",
    "\n",
    "#### **Strategy 4: Two-Stage Training**\n",
    "1. **Stage 1**: Train on balanced subset (filter \"None\" heavily)\n",
    "2. **Stage 2**: Fine-tune on full dataset with class weights\n",
    "\n",
    "‚úÖ **Pros**: Best of both worlds\n",
    "‚ùå **Cons**: Takes more time\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ **Recommended Approach for Your Dataset**\n",
    "\n",
    "Based on the file analysis showing severe \"None\" dominance:\n",
    "\n",
    "1. **Start with**: Class weights (already enabled in config)\n",
    "2. **If results are poor**: Enable \"None\" filtering:\n",
    "   ```python\n",
    "   imbalance_config[\"filter_none_samples\"] = True\n",
    "   imbalance_config[\"none_keep_ratio\"] = 0.4  # Keep 40% of \"None\"\n",
    "   ```\n",
    "3. **Monitor**: Per-class F1 scores (especially for \"Issue\", \"Decision\")\n",
    "4. **Adjust**: If minority classes still perform poorly, reduce `none_keep_ratio` to 0.2-0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0127ac1a",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b24006e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Exploring Training Data\n",
      "üìÇ Exploring dataset: /home/nyaya/server/dataset/Hier_BiLSTM_CRF/train\n",
      "üìÑ Found 4994 files\n",
      "\n",
      "üìù File: file_1.txt\n",
      "  Sentences in this file: 0\n",
      "\n",
      "üìù File: file_10.txt\n",
      "  Sentences in this file: 0\n",
      "\n",
      "üìù File: file_100.txt\n",
      "  Sentences in this file: 0\n",
      "\n",
      "üìù File: file_1000.txt\n",
      "  Sentences in this file: 0\n",
      "\n",
      "üìù File: file_1002.txt\n",
      "  Sentences in this file: 0\n",
      "\n",
      "üìä Dataset Statistics:\n",
      "  Total files: 4994\n",
      "  Total documents: 0\n",
      "  Total sentences: 0\n",
      "  Average sentences per document: 0.0\n",
      "\n",
      "üè∑Ô∏è Role Distribution:\n"
     ]
    }
   ],
   "source": [
    "# Explore your dataset\n",
    "def explore_dataset(data_path):\n",
    "    \"\"\"Explore the structure and statistics of your dataset\"\"\"\n",
    "    data_path = Path(data_path)\n",
    "    \n",
    "    if not data_path.exists():\n",
    "        print(f\"‚ùå Data path does not exist: {data_path}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"üìÇ Exploring dataset: {data_path}\")\n",
    "    \n",
    "    if data_path.is_file():\n",
    "        files = [data_path]\n",
    "    else:\n",
    "        files = list(data_path.glob(\"*.txt\"))\n",
    "    \n",
    "    print(f\"üìÑ Found {len(files)} files\")\n",
    "    \n",
    "    total_sentences = 0\n",
    "    total_documents = 0\n",
    "    role_counts = {}\n",
    "    \n",
    "    for file_path in files[:5]:  # Check first 5 files\n",
    "        print(f\"\\nüìù File: {file_path.name}\")\n",
    "        \n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read().strip()\n",
    "        \n",
    "        lines = content.split('\\n')\n",
    "        doc_sentences = 0\n",
    "        \n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                if doc_sentences > 0:\n",
    "                    total_documents += 1\n",
    "                    doc_sentences = 0\n",
    "                continue\n",
    "            \n",
    "            parts = line.split('\\t')\n",
    "            if len(parts) >= 2:\n",
    "                sentence = parts[0].strip()\n",
    "                role = parts[1].strip()\n",
    "                \n",
    "                total_sentences += 1\n",
    "                doc_sentences += 1\n",
    "                role_counts[role] = role_counts.get(role, 0) + 1\n",
    "        \n",
    "        if doc_sentences > 0:\n",
    "            total_documents += 1\n",
    "        \n",
    "        print(f\"  Sentences in this file: {doc_sentences}\")\n",
    "    \n",
    "    print(f\"\\nüìä Dataset Statistics:\")\n",
    "    print(f\"  Total files: {len(files)}\")\n",
    "    print(f\"  Total documents: {total_documents}\")\n",
    "    print(f\"  Total sentences: {total_sentences}\")\n",
    "    print(f\"  Average sentences per document: {total_sentences/max(total_documents, 1):.1f}\")\n",
    "    \n",
    "    print(f\"\\nüè∑Ô∏è Role Distribution:\")\n",
    "    for role, count in sorted(role_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "        percentage = (count / total_sentences) * 100\n",
    "        print(f\"  {role}: {count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    return role_counts\n",
    "\n",
    "# Explore training data\n",
    "print(\"üîç Exploring Training Data\")\n",
    "train_role_counts = explore_dataset(config[\"train_data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f1fd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize role distribution\n",
    "if train_role_counts:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    roles = list(train_role_counts.keys())\n",
    "    counts = list(train_role_counts.values())\n",
    "    \n",
    "    plt.bar(roles, counts, color='skyblue', alpha=0.7)\n",
    "    plt.title('Role Distribution in Training Data', fontsize=16)\n",
    "    plt.xlabel('Rhetorical Role', fontsize=12)\n",
    "    plt.ylabel('Number of Sentences', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, v in enumerate(counts):\n",
    "        plt.text(i, v + max(counts)*0.01, str(v), ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Pie chart\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.pie(counts, labels=roles, autopct='%1.1f%%', startangle=90)\n",
    "    plt.title('Role Distribution (Percentage)', fontsize=16)\n",
    "    plt.axis('equal')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314b23a0",
   "metadata": {},
   "source": [
    "## Data Loading and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f586bdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data loading\n",
    "print(\"üîÑ Testing Data Loading...\")\n",
    "\n",
    "try:\n",
    "    # Create data loaders\n",
    "    data_loaders = create_data_loaders(\n",
    "        train_path=config[\"train_data\"],\n",
    "        val_path=config[\"val_data\"],\n",
    "        test_path=config[\"test_data\"],\n",
    "        tokenizer_name=config[\"model_name\"],\n",
    "        context_mode=config[\"context_mode\"],\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        max_length=config[\"max_length\"]\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Data loaders created successfully!\")\n",
    "    print(f\"üì¶ Training batches: {len(data_loaders['train'])}\")\n",
    "    print(f\"üì¶ Validation batches: {len(data_loaders['val'])}\")\n",
    "    if 'test' in data_loaders:\n",
    "        print(f\"üì¶ Test batches: {len(data_loaders['test'])}\")\n",
    "    \n",
    "    # Check a sample batch\n",
    "    sample_batch = next(iter(data_loaders['train']))\n",
    "    print(f\"\\nüîç Sample Batch Shape:\")\n",
    "    print(f\"  Input IDs: {sample_batch['input_ids'].shape}\")\n",
    "    print(f\"  Attention Mask: {sample_batch['attention_mask'].shape}\")\n",
    "    print(f\"  Labels: {sample_batch['labels'].shape}\")\n",
    "    print(f\"  Unique labels in batch: {torch.unique(sample_batch['labels'])}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading data: {e}\")\n",
    "    print(\"Please check your data paths and format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e2ba72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample some examples from the dataset\n",
    "try:\n",
    "    sample_batch = next(iter(data_loaders['train']))\n",
    "    \n",
    "    print(\"üìù Sample Training Examples:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Show first 3 examples\n",
    "    for i in range(min(3, len(sample_batch['text']))):\n",
    "        text = sample_batch['text'][i]\n",
    "        label_id = sample_batch['labels'][i].item()\n",
    "        \n",
    "        # Map label ID to role name\n",
    "        role_names = [role.value for role in RhetoricalRole]\n",
    "        role_name = role_names[label_id] if label_id < len(role_names) else \"Unknown\"\n",
    "        \n",
    "        print(f\"\\nExample {i+1}:\")\n",
    "        print(f\"Text: {text[:200]}{'...' if len(text) > 200 else ''}\")\n",
    "        print(f\"Role: {role_name} (ID: {label_id})\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error sampling examples: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16b03cd",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592f18a9",
   "metadata": {},
   "source": [
    "## üîß Preprocessing Raw Test/Val Data\n",
    "\n",
    "**Problem Detected**: Your test and validation datasets contain **raw legal text** without labels (not in `sentence\\trole` format).\n",
    "\n",
    "**Solution**: We need to:\n",
    "1. Use the **trained model** to predict labels for test/val data\n",
    "2. Create labeled versions for evaluation\n",
    "3. Or evaluate directly on raw text if you have gold labels separately\n",
    "\n",
    "### Two Scenarios:\n",
    "\n",
    "#### **Scenario A: You have gold labels separately**\n",
    "- Test/val files are raw text\n",
    "- Gold labels exist in another file/format\n",
    "- **Action**: Use the preprocessing cell below\n",
    "\n",
    "#### **Scenario B: No gold labels (truly unlabeled data)**\n",
    "- Test/val files are just for inference\n",
    "- No evaluation possible\n",
    "- **Action**: Use the model to predict and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e82cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess raw legal documents for testing\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "def preprocess_raw_document(file_path, output_path=None):\n",
    "    \"\"\"\n",
    "    Convert raw legal document to sentence\\trole format for testing.\n",
    "    Initially labels everything as 'None' - will be relabeled by model.\n",
    "    \"\"\"\n",
    "    # Load spacy for sentence segmentation\n",
    "    try:\n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "    except:\n",
    "        print(\"‚ö†Ô∏è  Installing spacy model...\")\n",
    "        import subprocess\n",
    "        subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", \"en_core_web_sm\"])\n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "    \n",
    "    # Read raw text\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        raw_text = f.read()\n",
    "    \n",
    "    # Clean text\n",
    "    raw_text = re.sub(r'\\s+', ' ', raw_text)  # Remove extra whitespace\n",
    "    raw_text = raw_text.strip()\n",
    "    \n",
    "    # Segment into sentences\n",
    "    doc = nlp(raw_text)\n",
    "    sentences = [sent.text.strip() for sent in doc.sents if sent.text.strip()]\n",
    "    \n",
    "    # Create labeled format (initially all 'None')\n",
    "    labeled_lines = []\n",
    "    for sentence in sentences:\n",
    "        if len(sentence) > 10:  # Filter very short sentences\n",
    "            labeled_lines.append(f\"{sentence}\\tNone\")\n",
    "    \n",
    "    # Save if output path provided\n",
    "    if output_path:\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            f.write('\\n'.join(labeled_lines))\n",
    "        print(f\"‚úÖ Preprocessed: {output_path}\")\n",
    "    \n",
    "    return labeled_lines\n",
    "\n",
    "# Test on a sample file\n",
    "sample_test_file = Path(config[\"test_data\"]) / \"file_6409.txt\"\n",
    "if sample_test_file.exists():\n",
    "    print(\"üîç Testing preprocessing on sample file...\")\n",
    "    result = preprocess_raw_document(sample_test_file)\n",
    "    print(f\"üìä Extracted {len(result)} sentences\")\n",
    "    print(f\"\\nüìù Sample preprocessed output:\")\n",
    "    for line in result[:3]:\n",
    "        parts = line.split('\\t')\n",
    "        print(f\"  Sentence: {parts[0][:80]}...\")\n",
    "        print(f\"  Label: {parts[1]}\\n\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Sample test file not found. Check your test data path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3dd224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch preprocess all test/val files\n",
    "def batch_preprocess_dataset(input_dir, output_dir, max_files=None):\n",
    "    \"\"\"\n",
    "    Preprocess all raw files in a directory\n",
    "    \"\"\"\n",
    "    input_path = Path(input_dir)\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    files = list(input_path.glob(\"*.txt\"))\n",
    "    if max_files:\n",
    "        files = files[:max_files]\n",
    "    \n",
    "    print(f\"üìÇ Processing {len(files)} files from {input_dir}\")\n",
    "    print(f\"üìÇ Output directory: {output_dir}\")\n",
    "    \n",
    "    total_sentences = 0\n",
    "    \n",
    "    for i, file_path in enumerate(files, 1):\n",
    "        output_file = output_path / file_path.name\n",
    "        labeled_lines = preprocess_raw_document(file_path, output_file)\n",
    "        total_sentences += len(labeled_lines)\n",
    "        \n",
    "        if i % 50 == 0:\n",
    "            print(f\"  Processed {i}/{len(files)} files...\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Preprocessing complete!\")\n",
    "    print(f\"   Total files: {len(files)}\")\n",
    "    print(f\"   Total sentences: {total_sentences:,}\")\n",
    "    print(f\"   Average sentences per file: {total_sentences/len(files):.1f}\")\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "# Option to preprocess test and val datasets\n",
    "preprocess_data = False  # Set to True to preprocess\n",
    "\n",
    "if preprocess_data:\n",
    "    print(\"üîÑ Preprocessing Test Dataset...\")\n",
    "    preprocessed_test_dir = batch_preprocess_dataset(\n",
    "        input_dir=config[\"test_data\"],\n",
    "        output_dir=str(PROJECT_ROOT / \"dataset\" / \"Hier_BiLSTM_CRF\" / \"test_preprocessed\"),\n",
    "        max_files=None  # Process all files\n",
    "    )\n",
    "    \n",
    "    print(\"\\nüîÑ Preprocessing Validation Dataset...\")\n",
    "    preprocessed_val_dir = batch_preprocess_dataset(\n",
    "        input_dir=config[\"val_data\"],\n",
    "        output_dir=str(PROJECT_ROOT / \"dataset\" / \"Hier_BiLSTM_CRF\" / \"val_preprocessed\"),\n",
    "        max_files=None\n",
    "    )\n",
    "    \n",
    "    # Update config to use preprocessed data\n",
    "    config[\"test_data\"] = str(preprocessed_test_dir)\n",
    "    config[\"val_data\"] = str(preprocessed_val_dir)\n",
    "    \n",
    "    print(\"\\n‚úÖ Config updated to use preprocessed data\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Preprocessing disabled. Set preprocess_data=True to enable.\")\n",
    "    print(\"   Current approach: Assuming test/val data is already in correct format.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9abf8f",
   "metadata": {},
   "source": [
    "### Alternative: Predict and Evaluate Without Gold Labels\n",
    "\n",
    "If you don't have gold labels for test/val data, you can:\n",
    "1. **Use the trained model to predict** on raw documents\n",
    "2. **Manually review** a sample of predictions\n",
    "3. **Calculate inter-annotator agreement** if you have multiple annotators\n",
    "\n",
    "This approach is useful for:\n",
    "- **Unlabeled inference**: Classify new documents\n",
    "- **Semi-supervised learning**: Use predictions to create training data\n",
    "- **Active learning**: Identify uncertain predictions for manual labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ce4ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference on raw documents (no gold labels needed)\n",
    "def predict_on_raw_document(model_evaluator, file_path, context_mode=\"prev\"):\n",
    "    \"\"\"\n",
    "    Predict roles for a raw legal document\n",
    "    \"\"\"\n",
    "    # Read and preprocess\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        raw_text = f.read()\n",
    "    \n",
    "    # Segment sentences\n",
    "    try:\n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "    except:\n",
    "        print(\"Loading spacy model...\")\n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "    \n",
    "    doc = nlp(raw_text)\n",
    "    sentences = [sent.text.strip() for sent in doc.sents if sent.text.strip() and len(sent.text.strip()) > 10]\n",
    "    \n",
    "    # Predict for each sentence\n",
    "    predictions = []\n",
    "    for sentence in sentences:\n",
    "        try:\n",
    "            result = model_evaluator.predict_single(sentence, context_mode=context_mode)\n",
    "            predictions.append({\n",
    "                'sentence': sentence,\n",
    "                'predicted_role': result['predicted_role'],\n",
    "                'confidence': result['confidence']\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Error predicting: {str(e)[:50]}\")\n",
    "            predictions.append({\n",
    "                'sentence': sentence,\n",
    "                'predicted_role': 'None',\n",
    "                'confidence': 0.0\n",
    "            })\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "def save_predictions(predictions, output_path):\n",
    "    \"\"\"Save predictions in sentence\\trole format\"\"\"\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        for pred in predictions:\n",
    "            f.write(f\"{pred['sentence']}\\t{pred['predicted_role']}\\n\")\n",
    "    print(f\"‚úÖ Saved predictions to: {output_path}\")\n",
    "\n",
    "# Example usage (after model is trained)\n",
    "# This cell should be run AFTER training is complete\n",
    "inference_mode = False  # Set to True after training\n",
    "\n",
    "if inference_mode and 'evaluator' in locals():\n",
    "    print(\"üîÆ Running inference on raw test document...\")\n",
    "    \n",
    "    # Pick a test file\n",
    "    test_file = Path(config[\"test_data\"]) / \"file_6409.txt\"\n",
    "    \n",
    "    if test_file.exists():\n",
    "        predictions = predict_on_raw_document(evaluator, test_file, context_mode=config[\"context_mode\"])\n",
    "        \n",
    "        # Display summary\n",
    "        print(f\"\\nüìä Prediction Summary:\")\n",
    "        print(f\"   Total sentences: {len(predictions)}\")\n",
    "        \n",
    "        role_dist = {}\n",
    "        for pred in predictions:\n",
    "            role = pred['predicted_role']\n",
    "            role_dist[role] = role_dist.get(role, 0) + 1\n",
    "        \n",
    "        print(f\"\\nüè∑Ô∏è Predicted Role Distribution:\")\n",
    "        for role, count in sorted(role_dist.items(), key=lambda x: x[1], reverse=True):\n",
    "            percentage = (count / len(predictions)) * 100\n",
    "            print(f\"   {role:<30} {count:>5} ({percentage:>5.1f}%)\")\n",
    "        \n",
    "        # Show sample predictions\n",
    "        print(f\"\\nüìù Sample Predictions:\")\n",
    "        for i, pred in enumerate(predictions[:5], 1):\n",
    "            print(f\"\\n{i}. Sentence: {pred['sentence'][:80]}...\")\n",
    "            print(f\"   Predicted: {pred['predicted_role']} (confidence: {pred['confidence']:.3f})\")\n",
    "        \n",
    "        # Save predictions\n",
    "        output_path = Path(config[\"output_dir\"]) / \"predictions_file_6409.txt\"\n",
    "        save_predictions(predictions, output_path)\n",
    "    else:\n",
    "        print(f\"‚ùå Test file not found: {test_file}\")\n",
    "else:\n",
    "    if not inference_mode:\n",
    "        print(\"‚ö†Ô∏è  Inference mode disabled. Set inference_mode=True after training.\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Model evaluator not available. Train the model first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d27ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer\n",
    "print(\"üöÄ Initializing Role Classifier Trainer...\")\n",
    "\n",
    "# Create output directory with timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir = Path(config[\"output_dir\"]) / f\"{config['model_type']}_{timestamp}\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"üìÇ Output directory: {output_dir}\")\n",
    "\n",
    "try:\n",
    "    trainer = RoleClassifierTrainer(\n",
    "        model_type=config[\"model_type\"],\n",
    "        model_name=config[\"model_name\"],\n",
    "        device=config[\"device\"],\n",
    "        output_dir=str(output_dir),\n",
    "        num_labels=7  # 7 rhetorical roles\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Trainer initialized successfully!\")\n",
    "    print(f\"üñ•Ô∏è  Using device: {config['device']}\")\n",
    "    print(f\"ü§ñ Model type: {config['model_type']}\")\n",
    "    print(f\"üìè Model parameters: {sum(p.numel() for p in trainer.model.parameters()):,}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error initializing trainer: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6aa2486",
   "metadata": {},
   "source": [
    "## üíæ Memory Optimization for Large Datasets (Kaggle/Colab)\n",
    "\n",
    "**Problem**: Training on large datasets can cause:\n",
    "- ‚ùå Out of memory errors when saving checkpoints\n",
    "- ‚ùå Kaggle kernel crashes\n",
    "- ‚ùå Slow training due to memory swapping\n",
    "\n",
    "**Solutions**:\n",
    "1. **Gradient Accumulation**: Simulate larger batches without memory overhead\n",
    "2. **Checkpointing Strategy**: Save only essential weights, not optimizer states\n",
    "3. **Mixed Precision Training**: Use FP16 to reduce memory by 50%\n",
    "4. **Data Streaming**: Load batches on-the-fly instead of all at once\n",
    "5. **Periodic Cleanup**: Clear cache and garbage collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f37e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory optimization configuration for Kaggle/Colab\n",
    "memory_config = {\n",
    "    # Strategy 1: Reduce batch size\n",
    "    \"reduced_batch_size\": 8,  # Down from 16\n",
    "    \"gradient_accumulation_steps\": 2,  # Effective batch size = 8 * 2 = 16\n",
    "    \n",
    "    # Strategy 2: Mixed precision training (FP16)\n",
    "    \"use_mixed_precision\": True,  # Reduces memory by ~50%\n",
    "    \n",
    "    # Strategy 3: Checkpoint saving\n",
    "    \"save_frequency\": \"epoch\",  # Options: \"epoch\", \"steps\", or number\n",
    "    \"save_optimizer_state\": False,  # Don't save optimizer (saves 50% space)\n",
    "    \"keep_only_best\": True,  # Delete intermediate checkpoints\n",
    "    \n",
    "    # Strategy 4: Data loading\n",
    "    \"num_workers\": 2,  # Reduce data loader workers\n",
    "    \"pin_memory\": False,  # Disable if running out of memory\n",
    "    \n",
    "    # Strategy 5: Periodic cleanup\n",
    "    \"clear_cache_every\": 100,  # Clear CUDA cache every N steps\n",
    "    \"garbage_collect_every\": 500,  # Run garbage collection\n",
    "    \n",
    "    # Strategy 6: Reduce training data (for testing)\n",
    "    \"use_subset\": False,  # Set True to use only subset for quick testing\n",
    "    \"subset_ratio\": 0.2,  # Use 20% of training data\n",
    "}\n",
    "\n",
    "print(\"üíæ Memory Optimization Configuration:\")\n",
    "print(\"=\" * 60)\n",
    "for key, value in memory_config.items():\n",
    "    print(f\"  {key:<30} ‚Üí {value}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Calculate effective batch size\n",
    "if memory_config[\"gradient_accumulation_steps\"] > 1:\n",
    "    effective_batch_size = (\n",
    "        memory_config[\"reduced_batch_size\"] * \n",
    "        memory_config[\"gradient_accumulation_steps\"]\n",
    "    )\n",
    "    print(f\"\\nüìä Effective batch size: {effective_batch_size}\")\n",
    "    print(f\"   (Physical: {memory_config['reduced_batch_size']} √ó \"\n",
    "          f\"Accumulation: {memory_config['gradient_accumulation_steps']})\")\n",
    "\n",
    "if memory_config[\"use_mixed_precision\"]:\n",
    "    print(f\"\\n‚úÖ Mixed precision (FP16) enabled\")\n",
    "    print(f\"   ‚Üí ~50% memory reduction\")\n",
    "    print(f\"   ‚Üí ~2x speed improvement on modern GPUs\")\n",
    "\n",
    "if not memory_config[\"save_optimizer_state\"]:\n",
    "    print(f\"\\n‚úÖ Optimizer states excluded from checkpoints\")\n",
    "    print(f\"   ‚Üí ~50% smaller checkpoint files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b4f206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check current memory usage (Kaggle/Colab)\n",
    "import gc\n",
    "import psutil\n",
    "\n",
    "def check_memory_usage():\n",
    "    \"\"\"Check CPU and GPU memory usage\"\"\"\n",
    "    # CPU Memory\n",
    "    process = psutil.Process()\n",
    "    cpu_memory_mb = process.memory_info().rss / 1024 / 1024\n",
    "    \n",
    "    vm = psutil.virtual_memory()\n",
    "    total_memory_gb = vm.total / 1024 / 1024 / 1024\n",
    "    available_memory_gb = vm.available / 1024 / 1024 / 1024\n",
    "    used_percent = vm.percent\n",
    "    \n",
    "    print(\"üíæ Memory Status:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"üìä CPU Memory:\")\n",
    "    print(f\"   Process: {cpu_memory_mb:.1f} MB\")\n",
    "    print(f\"   Total: {total_memory_gb:.1f} GB\")\n",
    "    print(f\"   Available: {available_memory_gb:.1f} GB\")\n",
    "    print(f\"   Used: {used_percent:.1f}%\")\n",
    "    \n",
    "    # GPU Memory\n",
    "    if torch.cuda.is_available():\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            allocated = torch.cuda.memory_allocated(i) / 1024 / 1024 / 1024\n",
    "            reserved = torch.cuda.memory_reserved(i) / 1024 / 1024 / 1024\n",
    "            total = torch.cuda.get_device_properties(i).total_memory / 1024 / 1024 / 1024\n",
    "            \n",
    "            print(f\"\\nüéÆ GPU {i} ({torch.cuda.get_device_name(i)}):\")\n",
    "            print(f\"   Allocated: {allocated:.2f} GB\")\n",
    "            print(f\"   Reserved: {reserved:.2f} GB\")\n",
    "            print(f\"   Total: {total:.2f} GB\")\n",
    "            print(f\"   Used: {(allocated/total)*100:.1f}%\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è  No GPU available\")\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Warning if memory is high\n",
    "    if used_percent > 80:\n",
    "        print(\"\\n‚ö†Ô∏è  WARNING: CPU memory usage is high (>80%)\")\n",
    "        print(\"   Consider enabling memory optimization strategies\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        gpu_used_percent = (torch.cuda.memory_allocated(0) / \n",
    "                           torch.cuda.get_device_properties(0).total_memory) * 100\n",
    "        if gpu_used_percent > 80:\n",
    "            print(\"\\n‚ö†Ô∏è  WARNING: GPU memory usage is high (>80%)\")\n",
    "            print(\"   Consider:\")\n",
    "            print(\"   - Reducing batch size\")\n",
    "            print(\"   - Enabling mixed precision\")\n",
    "            print(\"   - Clearing CUDA cache\")\n",
    "\n",
    "# Check memory before training\n",
    "print(\"üîç Checking memory before training...\\n\")\n",
    "check_memory_usage()\n",
    "\n",
    "# Cleanup to free memory\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"\\n‚úÖ Garbage collection and CUDA cache cleared\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f490339d",
   "metadata": {},
   "source": [
    "### üîß Apply Memory Optimizations to Config\n",
    "\n",
    "Based on the memory check above, update your training configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117f601b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply memory optimizations to training config\n",
    "# Run this cell to update your config for memory-constrained environments\n",
    "\n",
    "apply_memory_optimizations = True  # Set to True for Kaggle/Colab\n",
    "\n",
    "if apply_memory_optimizations:\n",
    "    print(\"‚öôÔ∏è  Applying memory optimizations to training config...\\n\")\n",
    "    \n",
    "    # Store original values\n",
    "    original_batch_size = config[\"batch_size\"]\n",
    "    \n",
    "    # Update config with memory-optimized settings\n",
    "    config.update({\n",
    "        \"batch_size\": memory_config[\"reduced_batch_size\"],\n",
    "        \"gradient_accumulation_steps\": memory_config[\"gradient_accumulation_steps\"],\n",
    "        \"use_mixed_precision\": memory_config[\"use_mixed_precision\"],\n",
    "        \"num_workers\": memory_config[\"num_workers\"],\n",
    "        \"pin_memory\": memory_config[\"pin_memory\"],\n",
    "        \"save_optimizer_state\": memory_config[\"save_optimizer_state\"],\n",
    "        \"clear_cache_frequency\": memory_config[\"clear_cache_every\"],\n",
    "    })\n",
    "    \n",
    "    print(\"‚úÖ Configuration updated for memory optimization:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"  batch_size: {original_batch_size} ‚Üí {config['batch_size']}\")\n",
    "    print(f\"  gradient_accumulation_steps: {config['gradient_accumulation_steps']}\")\n",
    "    print(f\"  Effective batch size: {config['batch_size'] * config['gradient_accumulation_steps']}\")\n",
    "    print(f\"  use_mixed_precision: {config['use_mixed_precision']}\")\n",
    "    print(f\"  save_optimizer_state: {config['save_optimizer_state']}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Optional: Use subset for quick testing\n",
    "    if memory_config[\"use_subset\"]:\n",
    "        print(f\"\\n‚ö†Ô∏è  Using {memory_config['subset_ratio']*100:.0f}% of training data (subset mode)\")\n",
    "        config[\"use_data_subset\"] = True\n",
    "        config[\"subset_ratio\"] = memory_config[\"subset_ratio\"]\n",
    "    \n",
    "    print(\"\\nüí° Memory-saving features enabled:\")\n",
    "    print(\"   ‚úÖ Smaller batch size with gradient accumulation\")\n",
    "    print(\"   ‚úÖ Mixed precision training (FP16)\")\n",
    "    print(\"   ‚úÖ Lighter checkpoints (no optimizer state)\")\n",
    "    print(\"   ‚úÖ Periodic cache clearing\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Memory optimizations NOT applied.\")\n",
    "    print(\"   Set apply_memory_optimizations=True to enable.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd5bd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "print(\"üéØ Starting Training...\")\n",
    "print(f\"‚è±Ô∏è  Training for {config['num_epochs']} epochs\")\n",
    "print(f\"üìö Batch size: {config['batch_size']}\")\n",
    "print(f\"üß† Learning rate: {config['learning_rate']}\")\n",
    "print(f\"üìù Context mode: {config['context_mode']}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # Train the model\n",
    "    trainer.train(\n",
    "        train_data_path=config[\"train_data\"],\n",
    "        val_data_path=config[\"val_data\"],\n",
    "        test_data_path=config[\"test_data\"],\n",
    "        context_mode=config[\"context_mode\"],\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        num_epochs=config[\"num_epochs\"],\n",
    "        learning_rate=config[\"learning_rate\"],\n",
    "        weight_decay=config[\"weight_decay\"],\n",
    "        warmup_steps=config[\"warmup_steps\"],\n",
    "        max_length=config[\"max_length\"],\n",
    "        save_best_model=config[\"save_best_model\"]\n",
    "    )\n",
    "    \n",
    "    print(\"\\nüéâ Training completed successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Training failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76074cc",
   "metadata": {},
   "source": [
    "## Training Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c96c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display training history\n",
    "history_path = output_dir / \"training_history.json\"\n",
    "\n",
    "if history_path.exists():\n",
    "    with open(history_path, 'r') as f:\n",
    "        history = json.load(f)\n",
    "    \n",
    "    print(\"üìà Training History:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Display final metrics\n",
    "    if history:\n",
    "        final_train_loss = history['train_loss'][-1] if history['train_loss'] else 'N/A'\n",
    "        final_val_loss = history['val_loss'][-1] if history['val_loss'] else 'N/A'\n",
    "        final_train_f1 = history['train_f1'][-1] if history['train_f1'] else 'N/A'\n",
    "        final_val_f1 = history['val_f1'][-1] if history['val_f1'] else 'N/A'\n",
    "        \n",
    "        print(f\"Final Training Loss: {final_train_loss:.4f}\" if isinstance(final_train_loss, float) else f\"Final Training Loss: {final_train_loss}\")\n",
    "        print(f\"Final Validation Loss: {final_val_loss:.4f}\" if isinstance(final_val_loss, float) else f\"Final Validation Loss: {final_val_loss}\")\n",
    "        print(f\"Final Training F1: {final_train_f1:.4f}\" if isinstance(final_train_f1, float) else f\"Final Training F1: {final_train_f1}\")\n",
    "        print(f\"Final Validation F1: {final_val_f1:.4f}\" if isinstance(final_val_f1, float) else f\"Final Validation F1: {final_val_f1}\")\n",
    "        \n",
    "        # Plot training curves\n",
    "        if all(key in history and history[key] for key in ['epoch', 'train_loss', 'val_loss', 'train_f1', 'val_f1']):\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "            \n",
    "            # Loss plot\n",
    "            ax1.plot(history['epoch'], history['train_loss'], label='Train Loss', marker='o')\n",
    "            ax1.plot(history['epoch'], history['val_loss'], label='Val Loss', marker='s')\n",
    "            ax1.set_xlabel('Epoch')\n",
    "            ax1.set_ylabel('Loss')\n",
    "            ax1.set_title('Training and Validation Loss')\n",
    "            ax1.legend()\n",
    "            ax1.grid(True, alpha=0.3)\n",
    "            \n",
    "            # F1 Score plot\n",
    "            ax2.plot(history['epoch'], history['train_f1'], label='Train F1', marker='o')\n",
    "            ax2.plot(history['epoch'], history['val_f1'], label='Val F1', marker='s')\n",
    "            ax2.set_xlabel('Epoch')\n",
    "            ax2.set_ylabel('F1 Score')\n",
    "            ax2.set_title('Training and Validation F1 Score')\n",
    "            ax2.legend()\n",
    "            ax2.grid(True, alpha=0.3)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "else:\n",
    "    print(\"‚ùå Training history not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cf2209",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b43b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the trained model\n",
    "print(\"üîç Evaluating Trained Model...\")\n",
    "\n",
    "# Path to the best model\n",
    "best_model_path = output_dir / \"best_model.pt\"\n",
    "\n",
    "if best_model_path.exists():\n",
    "    try:\n",
    "        # Initialize evaluator\n",
    "        evaluator = ModelEvaluator(\n",
    "            model_path=str(best_model_path),\n",
    "            device=config[\"device\"]\n",
    "        )\n",
    "        \n",
    "        print(\"‚úÖ Evaluator initialized\")\n",
    "        \n",
    "        # Create evaluation output directory\n",
    "        eval_output_dir = output_dir / \"evaluation_results\"\n",
    "        \n",
    "        # Evaluate on test set\n",
    "        metrics = evaluator.evaluate_dataset(\n",
    "            test_data_path=config[\"test_data\"],\n",
    "            context_mode=config[\"context_mode\"],\n",
    "            batch_size=config[\"batch_size\"],\n",
    "            output_dir=str(eval_output_dir)\n",
    "        )\n",
    "        \n",
    "        print(\"\\nüéØ Evaluation Results:\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"üìä Accuracy: {metrics['accuracy']:.4f}\")\n",
    "        print(f\"üìä Weighted F1: {metrics['weighted_f1']:.4f}\")\n",
    "        print(f\"üìä Macro F1: {metrics['macro_f1']:.4f}\")\n",
    "        print(f\"üìä Weighted Precision: {metrics['weighted_precision']:.4f}\")\n",
    "        print(f\"üìä Weighted Recall: {metrics['weighted_recall']:.4f}\")\n",
    "        \n",
    "        # Display per-class metrics\n",
    "        if 'per_class' in metrics:\n",
    "            print(\"\\nüìà Per-Class Metrics:\")\n",
    "            print(\"-\" * 60)\n",
    "            for role, class_metrics in metrics['per_class'].items():\n",
    "                print(f\"{role:20} | F1: {class_metrics['f1']:.3f} | Prec: {class_metrics['precision']:.3f} | Rec: {class_metrics['recall']:.3f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Evaluation failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(f\"‚ùå Best model not found at {best_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf4fd72",
   "metadata": {},
   "source": [
    "## Test Single Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadcf96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test single predictions\n",
    "if 'evaluator' in locals():\n",
    "    print(\"üß™ Testing Single Predictions...\")\n",
    "    \n",
    "    # Test sentences\n",
    "    test_sentences = [\n",
    "        \"The petitioner filed a writ petition challenging the constitutional validity of Section 377.\",\n",
    "        \"The main issue in this case is whether Section 377 violates fundamental rights.\",\n",
    "        \"The petitioner argues that Section 377 is discriminatory and violates Article 14.\",\n",
    "        \"The respondent contends that Section 377 is constitutionally valid and necessary.\",\n",
    "        \"The court finds that Section 377 infringes upon the right to privacy and equality.\",\n",
    "        \"Therefore, Section 377 is hereby declared unconstitutional and is struck down.\"\n",
    "    ]\n",
    "    \n",
    "    expected_roles = [\"Facts\", \"Issue\", \"Arguments of Petitioner\", \"Arguments of Respondent\", \"Reasoning\", \"Decision\"]\n",
    "    \n",
    "    print(\"\\nüìù Prediction Results:\")\n",
    "    print(\"=\" * 100)\n",
    "    \n",
    "    correct_predictions = 0\n",
    "    \n",
    "    for i, (sentence, expected) in enumerate(zip(test_sentences, expected_roles)):\n",
    "        result = evaluator.predict_single(sentence, context_mode=config[\"context_mode\"])\n",
    "        \n",
    "        predicted_role = result['predicted_role']\n",
    "        confidence = result['confidence']\n",
    "        \n",
    "        is_correct = predicted_role == expected\n",
    "        if is_correct:\n",
    "            correct_predictions += 1\n",
    "        \n",
    "        status = \"‚úÖ\" if is_correct else \"‚ùå\"\n",
    "        \n",
    "        print(f\"\\n{status} Example {i+1}:\")\n",
    "        print(f\"Text: {sentence[:80]}{'...' if len(sentence) > 80 else ''}\")\n",
    "        print(f\"Expected: {expected}\")\n",
    "        print(f\"Predicted: {predicted_role} (Confidence: {confidence:.3f})\")\n",
    "        \n",
    "        # Show top predictions\n",
    "        print(\"Top 3 predictions:\")\n",
    "        for j, pred in enumerate(result['top_predictions'][:3]):\n",
    "            print(f\"  {j+1}. {pred['role']}: {pred['confidence']:.3f}\")\n",
    "        print(\"-\" * 80)\n",
    "    \n",
    "    accuracy = correct_predictions / len(test_sentences)\n",
    "    print(f\"\\nüéØ Test Accuracy: {correct_predictions}/{len(test_sentences)} ({accuracy:.1%})\")\n",
    "else:\n",
    "    print(\"‚ùå Evaluator not available. Please complete the evaluation step first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33e3560",
   "metadata": {},
   "source": [
    "## Save and Load Model for Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7b066c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate how to save and load the model for production use\n",
    "print(\"üíæ Model Save/Load for Production\")\n",
    "\n",
    "if best_model_path.exists():\n",
    "    print(f\"\\nüìÇ Best model saved at: {best_model_path}\")\n",
    "    \n",
    "    # Show how to load the model in production\n",
    "    print(\"\\nüîß To use this model in your Nyaya system:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    production_code = f'''\n",
    "# In your production code (e.g., in role_classifier.py):\n",
    "from src.models.role_classifier import RoleClassifier\n",
    "\n",
    "# Initialize classifier\n",
    "classifier = RoleClassifier(\n",
    "    model_type=\"{config['model_type']}\",\n",
    "    device=\"{config['device']}\"\n",
    ")\n",
    "\n",
    "# Load your trained weights\n",
    "classifier.load_pretrained_weights(\"{best_model_path}\")\n",
    "\n",
    "# Use for classification\n",
    "results = classifier.classify_document(\n",
    "    document_text=\"Your legal document text here...\",\n",
    "    context_mode=\"{config['context_mode']}\"\n",
    ")\n",
    "'''\n",
    "    \n",
    "    print(production_code)\n",
    "    \n",
    "    # Save production instructions\n",
    "    instructions_path = output_dir / \"production_usage.py\"\n",
    "    with open(instructions_path, 'w') as f:\n",
    "        f.write(production_code)\n",
    "    \n",
    "    print(f\"\\nüìÑ Production usage instructions saved to: {instructions_path}\")\n",
    "    \n",
    "    # Model info\n",
    "    model_info = {\n",
    "        \"model_type\": config[\"model_type\"],\n",
    "        \"model_name\": config[\"model_name\"],\n",
    "        \"context_mode\": config[\"context_mode\"],\n",
    "        \"training_config\": config,\n",
    "        \"model_path\": str(best_model_path),\n",
    "        \"evaluation_metrics\": metrics if 'metrics' in locals() else None,\n",
    "        \"timestamp\": timestamp\n",
    "    }\n",
    "    \n",
    "    info_path = output_dir / \"model_info.json\"\n",
    "    with open(info_path, 'w') as f:\n",
    "        json.dump(model_info, f, indent=2, default=str)\n",
    "    \n",
    "    print(f\"üìã Model information saved to: {info_path}\")\n",
    "else:\n",
    "    print(\"‚ùå No trained model found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f38ca6",
   "metadata": {},
   "source": [
    "## Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1baa98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training summary\n",
    "print(\"üéä TRAINING SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if 'metrics' in locals():\n",
    "    print(f\"‚úÖ Training completed successfully!\")\n",
    "    print(f\"üìä Final Test Accuracy: {metrics['accuracy']:.4f}\")\n",
    "    print(f\"üìä Final Test F1 Score: {metrics['weighted_f1']:.4f}\")\n",
    "    print(f\"üìÇ Model saved at: {best_model_path}\")\n",
    "    print(f\"üìÇ Results saved at: {output_dir}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Training may not have completed successfully.\")\n",
    "    print(\"Please check the error messages above.\")\n",
    "\n",
    "print(\"\\nüöÄ NEXT STEPS:\")\n",
    "print(\"1. üìã Review the evaluation results and confusion matrix\")\n",
    "print(\"2. üîß Integrate the trained model into your Nyaya system\")\n",
    "print(\"3. üß™ Test with real legal documents\")\n",
    "print(\"4. üìà Consider further fine-tuning if needed\")\n",
    "print(\"5. üîÑ Update the role_classifier.py to use your trained weights\")\n",
    "\n",
    "print(\"\\nüìö FILES GENERATED:\")\n",
    "if output_dir.exists():\n",
    "    generated_files = list(output_dir.rglob(\"*\"))\n",
    "    for file_path in generated_files:\n",
    "        if file_path.is_file():\n",
    "            print(f\"  üìÑ {file_path.relative_to(output_dir)}\")\n",
    "else:\n",
    "    print(\"  ‚ùå No output directory found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7bdc88",
   "metadata": {},
   "source": [
    "## Optional: Hyperparameter Tuning\n",
    "\n",
    "If you want to experiment with different hyperparameters, you can modify the configuration and re-run the training cells above. Consider trying:\n",
    "\n",
    "- Different context modes: `\"single\"`, `\"prev_two\"`, `\"surrounding\"`\n",
    "- Different learning rates: `1e-5`, `3e-5`, `5e-5`\n",
    "- Different batch sizes: `8`, `32` (depending on your GPU memory)\n",
    "- More epochs for better convergence\n",
    "- Different model types: `\"bilstm_crf\"` for sequence modeling\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "1. **CUDA Out of Memory**: Reduce batch size or max_length\n",
    "2. **Low Accuracy**: Try more epochs, different context modes, or data augmentation\n",
    "3. **Import Errors**: Check file paths and ensure all dependencies are installed\n",
    "4. **Data Format Issues**: Ensure your data follows the sentence\\trole format with proper encoding"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
