{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intelligent Agent for Legal Document Analysis using RAG & Role Classifier\n",
    "\n",
    "## Complete Implementation in Jupyter Notebook\n",
    "\n",
    "This notebook contains the complete implementation of the Legal Document Analysis System with:\n",
    "1. **Role Classifier** - Segments legal documents into rhetorical roles\n",
    "2. **RAG System** - Role-aware retrieval-augmented generation\n",
    "3. **Agent Orchestrator** - Intelligent query routing\n",
    "4. **Conversation Manager** - Multi-turn dialogue support\n",
    "5. **Prediction Module** - Judgment outcome prediction\n",
    "6. **Document Processor** - PDF/text processing and metadata extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q fastapi uvicorn pydantic\n",
    "!pip install -q transformers torch spacy\n",
    "!pip install -q langchain langchain-community langchain-chroma chromadb\n",
    "!pip install -q PyMuPDF pypdf unstructured\n",
    "!pip install -q scikit-learn numpy pandas\n",
    "!pip install -q python-multipart  # For file uploads\n",
    "\n",
    "# Download spaCy model\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import uuid\n",
    "import base64\n",
    "import sqlite3\n",
    "import logging\n",
    "import asyncio\n",
    "import tempfile\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Any, Optional, Union, Tuple, BinaryIO\n",
    "from dataclasses import dataclass, asdict\n",
    "from enum import Enum\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "\n",
    "import spacy\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Document processing\n",
    "import fitz  # PyMuPDF\n",
    "from pypdf import PdfReader\n",
    "\n",
    "# ML and NLP\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# LangChain components\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.embeddings import VertexAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.chat_models import ChatVertexAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Core Enums and Data Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rhetorical Roles Enum\n",
    "class RhetoricalRole(Enum):\n",
    "    \"\"\"Rhetorical roles in legal documents\"\"\"\n",
    "    FACTS = \"Facts\"\n",
    "    ISSUE = \"Issue\"\n",
    "    ARGUMENTS_PETITIONER = \"Arguments of Petitioner\"\n",
    "    ARGUMENTS_RESPONDENT = \"Arguments of Respondent\"\n",
    "    REASONING = \"Reasoning\"\n",
    "    DECISION = \"Decision\"\n",
    "    NONE = \"None\"\n",
    "\n",
    "# Query Types\n",
    "class QueryType(Enum):\n",
    "    \"\"\"Types of user queries\"\"\"\n",
    "    DOCUMENT_ANALYSIS = \"document_analysis\"\n",
    "    ROLE_SPECIFIC_QUERY = \"role_specific_query\"\n",
    "    CASE_SUMMARY = \"case_summary\"\n",
    "    PRECEDENT_SEARCH = \"precedent_search\"\n",
    "    LEGAL_RESEARCH = \"legal_research\"\n",
    "    PROCEDURAL_QUERY = \"procedural_query\"\n",
    "    DOCUMENT_UPLOAD = \"document_upload\"\n",
    "    CONVERSATION_QUERY = \"conversation_query\"\n",
    "    PREDICTION_REQUEST = \"prediction_request\"\n",
    "\n",
    "# User Intent\n",
    "class Intent(Enum):\n",
    "    \"\"\"User intent categories\"\"\"\n",
    "    SEARCH = \"search\"\n",
    "    SUMMARIZE = \"summarize\"\n",
    "    ANALYZE = \"analyze\"\n",
    "    COMPARE = \"compare\"\n",
    "    EXPLAIN = \"explain\"\n",
    "    PREDICT = \"predict\"\n",
    "    UPLOAD = \"upload\"\n",
    "    CLARIFY = \"clarify\"\n",
    "\n",
    "# Message Types\n",
    "class MessageType(Enum):\n",
    "    \"\"\"Types of messages in conversation\"\"\"\n",
    "    USER = \"user\"\n",
    "    ASSISTANT = \"assistant\"\n",
    "    SYSTEM = \"system\"\n",
    "\n",
    "# Conversation Status\n",
    "class ConversationStatus(Enum):\n",
    "    \"\"\"Status of conversation session\"\"\"\n",
    "    ACTIVE = \"active\"\n",
    "    PAUSED = \"paused\"\n",
    "    ENDED = \"ended\"\n",
    "\n",
    "# Judgment Outcomes\n",
    "class JudgmentOutcome(Enum):\n",
    "    \"\"\"Possible judgment outcomes\"\"\"\n",
    "    ALLOWED = \"allowed\"\n",
    "    DISMISSED = \"dismissed\"\n",
    "    PARTLY_ALLOWED = \"partly_allowed\"\n",
    "    REMANDED = \"remanded\"\n",
    "    QUASHED = \"quashed\"\n",
    "    STAYED = \"stayed\"\n",
    "    REJECTED = \"rejected\"\n",
    "    WITHDRAWN = \"withdrawn\"\n",
    "\n",
    "# Case Types\n",
    "class CaseType(Enum):\n",
    "    \"\"\"Types of legal cases\"\"\"\n",
    "    CIVIL = \"civil\"\n",
    "    CRIMINAL = \"criminal\"\n",
    "    CONSTITUTIONAL = \"constitutional\"\n",
    "    COMMERCIAL = \"commercial\"\n",
    "    FAMILY = \"family\"\n",
    "    TAX = \"tax\"\n",
    "    LABOR = \"labor\"\n",
    "    PROPERTY = \"property\"\n",
    "\n",
    "print(\"Enums defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pydantic Models for API\n",
    "class QueryRequest(BaseModel):\n",
    "    \"\"\"Request model for legal queries\"\"\"\n",
    "    query: str = Field(..., description=\"Legal query text\")\n",
    "    session_id: Optional[str] = Field(None, description=\"Conversation session ID\")\n",
    "    context: Optional[Dict[str, Any]] = Field(None, description=\"Additional context\")\n",
    "    role_filter: Optional[List[str]] = Field(None, description=\"Filter by specific rhetorical roles\")\n",
    "\n",
    "class QueryResponse(BaseModel):\n",
    "    \"\"\"Response model for legal queries\"\"\"\n",
    "    answer: str = Field(..., description=\"Generated answer\")\n",
    "    session_id: str = Field(..., description=\"Conversation session ID\")\n",
    "    confidence: Optional[float] = Field(None, description=\"Response confidence score\")\n",
    "    sources: Optional[List[Dict[str, Any]]] = Field(None, description=\"Source documents\")\n",
    "    classification: Optional[Dict[str, Any]] = Field(None, description=\"Query classification\")\n",
    "    tools_used: Optional[List[str]] = Field(None, description=\"Tools used for processing\")\n",
    "\n",
    "class PredictionRequest(BaseModel):\n",
    "    \"\"\"Request model for judgment prediction\"\"\"\n",
    "    case_facts: str = Field(..., description=\"Facts of the case\")\n",
    "    case_issues: Optional[str] = Field(None, description=\"Legal issues\")\n",
    "    case_type: Optional[str] = Field(None, description=\"Type of case\")\n",
    "    session_id: Optional[str] = Field(None, description=\"Conversation session ID\")\n",
    "\n",
    "class PredictionResponse(BaseModel):\n",
    "    \"\"\"Response model for judgment prediction\"\"\"\n",
    "    predicted_outcome: str = Field(..., description=\"Predicted judgment outcome\")\n",
    "    confidence: float = Field(..., description=\"Prediction confidence\")\n",
    "    probability_distribution: Dict[str, float] = Field(..., description=\"Outcome probabilities\")\n",
    "    similar_cases: List[Dict[str, Any]] = Field(..., description=\"Similar precedent cases\")\n",
    "    key_factors: List[str] = Field(..., description=\"Key influencing factors\")\n",
    "    reasoning: str = Field(..., description=\"Prediction reasoning\")\n",
    "    disclaimer: str = Field(..., description=\"Legal disclaimer\")\n",
    "\n",
    "print(\"Pydantic models defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Role Classifier Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InLegalBERTClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    InLegalBERT-based classifier for rhetorical role classification\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"law-ai/InLegalBERT\", \n",
    "                 num_labels: int = 7, context_mode: str = \"single\"):\n",
    "        super().__init__()\n",
    "        self.context_mode = context_mode\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids=None):\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        \n",
    "        pooled_output = outputs.pooler_output\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "\n",
    "class RoleClassifier:\n",
    "    \"\"\"\n",
    "    Main role classifier interface supporting multiple models\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_type: str = \"inlegalbert\", device: str = \"cpu\"):\n",
    "        self.model_type = model_type\n",
    "        self.device = device\n",
    "        self.nlp = spacy.load(\"en_core_web_sm\")\n",
    "        self.model = None\n",
    "        self.role_to_id = {role.value: i for i, role in enumerate(RhetoricalRole)}\n",
    "        self.id_to_role = {i: role.value for i, role in enumerate(RhetoricalRole)}\n",
    "        \n",
    "        self._load_model()\n",
    "    \n",
    "    def _load_model(self):\n",
    "        \"\"\"Load the specified model\"\"\"\n",
    "        if self.model_type == \"inlegalbert\":\n",
    "            # For demo purposes, we'll use a simple rule-based classifier\n",
    "            # In production, load the actual trained model\n",
    "            self.model = None  # Placeholder\n",
    "            logger.info(f\"Loaded {self.model_type} model placeholder on {self.device}\")\n",
    "    \n",
    "    def preprocess_document(self, document_text: str) -> List[str]:\n",
    "        \"\"\"Preprocess legal document and extract sentences\"\"\"\n",
    "        doc = self.nlp(document_text)\n",
    "        sentences = [sent.text.strip() for sent in doc.sents if sent.text.strip()]\n",
    "        return sentences\n",
    "    \n",
    "    def classify_document(self, document_text: str, \n",
    "                         context_mode: str = \"single\") -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Classify rhetorical roles for all sentences in a document\n",
    "        Using rule-based classification for demo\n",
    "        \"\"\"\n",
    "        sentences = self.preprocess_document(document_text)\n",
    "        results = []\n",
    "        \n",
    "        for i, sentence in enumerate(sentences):\n",
    "            sentence_lower = sentence.lower()\n",
    "            \n",
    "            # Rule-based classification for demo\n",
    "            if any(word in sentence_lower for word in [\"facts\", \"happened\", \"incident\", \"events\"]):\n",
    "                role = RhetoricalRole.FACTS.value\n",
    "                confidence = 0.85\n",
    "            elif any(word in sentence_lower for word in [\"issue\", \"question\", \"whether\"]):\n",
    "                role = RhetoricalRole.ISSUE.value\n",
    "                confidence = 0.80\n",
    "            elif any(word in sentence_lower for word in [\"petitioner argues\", \"petitioner claims\"]):\n",
    "                role = RhetoricalRole.ARGUMENTS_PETITIONER.value\n",
    "                confidence = 0.90\n",
    "            elif any(word in sentence_lower for word in [\"respondent argues\", \"respondent contends\"]):\n",
    "                role = RhetoricalRole.ARGUMENTS_RESPONDENT.value\n",
    "                confidence = 0.90\n",
    "            elif any(word in sentence_lower for word in [\"court finds\", \"court analyzed\", \"reasoning\"]):\n",
    "                role = RhetoricalRole.REASONING.value\n",
    "                confidence = 0.85\n",
    "            elif any(word in sentence_lower for word in [\"dismissed\", \"allowed\", \"hereby\", \"ordered\"]):\n",
    "                role = RhetoricalRole.DECISION.value\n",
    "                confidence = 0.88\n",
    "            else:\n",
    "                role = RhetoricalRole.NONE.value\n",
    "                confidence = 0.60\n",
    "            \n",
    "            results.append({\n",
    "                \"sentence\": sentence,\n",
    "                \"role\": role,\n",
    "                \"confidence\": confidence,\n",
    "                \"sentence_index\": i\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "\n",
    "print(\"Role Classifier implementation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Document Processor Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentMetadata(BaseModel):\n",
    "    \"\"\"Metadata for processed legal documents\"\"\"\n",
    "    filename: str\n",
    "    file_type: str\n",
    "    case_name: Optional[str] = None\n",
    "    court: Optional[str] = None\n",
    "    date: Optional[str] = None\n",
    "    citation: Optional[str] = None\n",
    "    parties: Dict[str, str] = {}\n",
    "    page_count: int = 0\n",
    "    word_count: int = 0\n",
    "    processing_status: str = \"pending\"\n",
    "    error_message: Optional[str] = None\n",
    "\n",
    "class ProcessedDocument(BaseModel):\n",
    "    \"\"\"Processed legal document with extracted content and metadata\"\"\"\n",
    "    content: str\n",
    "    metadata: DocumentMetadata\n",
    "    sections: List[Dict[str, Any]] = []\n",
    "    extracted_entities: Dict[str, List[str]] = {}\n",
    "\n",
    "class LegalDocumentProcessor:\n",
    "    \"\"\"\n",
    "    Comprehensive document processor for legal documents\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, use_gpu: bool = False):\n",
    "        self.use_gpu = use_gpu\n",
    "        \n",
    "        try:\n",
    "            self.nlp = spacy.load(\"en_core_web_sm\")\n",
    "        except OSError:\n",
    "            logger.warning(\"spaCy English model not found. Some features may be limited.\")\n",
    "            self.nlp = None\n",
    "        \n",
    "        # Legal document patterns\n",
    "        self.case_name_patterns = [\n",
    "            r\"([A-Z][a-zA-Z\\s&\\.]+)\\s+v\\.?\\s+([A-Z][a-zA-Z\\s&\\.]+)\",\n",
    "            r\"([A-Z][a-zA-Z\\s&\\.]+)\\s+vs\\.?\\s+([A-Z][a-zA-Z\\s&\\.]+)\",\n",
    "        ]\n",
    "        \n",
    "        self.court_patterns = [\n",
    "            r\"Supreme\\s+Court\\s+of\\s+India\",\n",
    "            r\"High\\s+Court\\s+of\\s+[A-Za-z\\s]+\",\n",
    "        ]\n",
    "        \n",
    "        self.citation_patterns = [\n",
    "            r\"\\(\\d{4}\\)\\s+\\d+\\s+SCC\\s+\\d+\",\n",
    "            r\"AIR\\s+\\d{4}\\s+SC\\s+\\d+\",\n",
    "        ]\n",
    "        \n",
    "        logger.info(\"Legal Document Processor initialized\")\n",
    "    \n",
    "    def extract_text_from_txt(self, file_path: Union[str, BytesIO]) -> str:\n",
    "        \"\"\"Extract text from plain text file\"\"\"\n",
    "        try:\n",
    "            if isinstance(file_path, str):\n",
    "                with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                    return file.read()\n",
    "            else:\n",
    "                file_path.seek(0)\n",
    "                return file_path.read().decode('utf-8')\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to read text file: {e}\")\n",
    "            return \"\"\n",
    "    \n",
    "    def clean_text(self, text: str) -> str:\n",
    "        \"\"\"Clean and normalize legal document text\"\"\"\n",
    "        # Remove excessive whitespace\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        # Remove page numbers\n",
    "        text = re.sub(r'Page\\s+\\d+\\s+of\\s+\\d+', '', text)\n",
    "        # Fix common OCR errors in legal documents\n",
    "        text = re.sub(r'\\bvs\\b', 'v.', text)\n",
    "        return text.strip()\n",
    "    \n",
    "    def extract_case_metadata(self, text: str) -> Dict[str, Any]:\n",
    "        \"\"\"Extract legal-specific metadata from document text\"\"\"\n",
    "        metadata = {\n",
    "            \"case_name\": None,\n",
    "            \"court\": None,\n",
    "            \"citation\": None,\n",
    "            \"parties\": {},\n",
    "            \"date\": None\n",
    "        }\n",
    "        \n",
    "        # Extract case name\n",
    "        for pattern in self.case_name_patterns:\n",
    "            match = re.search(pattern, text[:2000])\n",
    "            if match:\n",
    "                metadata[\"case_name\"] = match.group(0)\n",
    "                metadata[\"parties\"] = {\n",
    "                    \"petitioner\": match.group(1).strip(),\n",
    "                    \"respondent\": match.group(2).strip()\n",
    "                }\n",
    "                break\n",
    "        \n",
    "        # Extract court information\n",
    "        for pattern in self.court_patterns:\n",
    "            match = re.search(pattern, text[:3000], re.IGNORECASE)\n",
    "            if match:\n",
    "                metadata[\"court\"] = match.group(0)\n",
    "                break\n",
    "        \n",
    "        return metadata\n",
    "\n",
    "print(\"Document Processor implementation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conversation Manager Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Message:\n",
    "    \"\"\"Individual message in conversation\"\"\"\n",
    "    id: str\n",
    "    content: str\n",
    "    message_type: MessageType\n",
    "    timestamp: datetime\n",
    "    metadata: Dict[str, Any] = None\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            \"id\": self.id,\n",
    "            \"content\": self.content,\n",
    "            \"message_type\": self.message_type.value,\n",
    "            \"timestamp\": self.timestamp.isoformat(),\n",
    "            \"metadata\": self.metadata or {}\n",
    "        }\n",
    "\n",
    "class ConversationSession(BaseModel):\n",
    "    \"\"\"Conversation session model\"\"\"\n",
    "    session_id: str\n",
    "    user_id: Optional[str] = None\n",
    "    title: str = \"Legal Consultation\"\n",
    "    status: ConversationStatus = ConversationStatus.ACTIVE\n",
    "    created_at: datetime\n",
    "    updated_at: datetime\n",
    "    messages: List[Message] = []\n",
    "    context: Dict[str, Any] = {}\n",
    "    metadata: Dict[str, Any] = {}\n",
    "    \n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "class ConversationMemory:\n",
    "    \"\"\"\n",
    "    Manages conversation memory including short-term and long-term storage\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, db_path: str = \"conversations.db\", max_short_term: int = 20):\n",
    "        self.db_path = db_path\n",
    "        self.max_short_term = max_short_term\n",
    "        self.active_sessions: Dict[str, ConversationSession] = {}\n",
    "        self._init_database()\n",
    "        logger.info(\"Conversation Memory initialized\")\n",
    "    \n",
    "    def _init_database(self):\n",
    "        \"\"\"Initialize SQLite database for conversation storage\"\"\"\n",
    "        Path(self.db_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        with sqlite3.connect(self.db_path) as conn:\n",
    "            conn.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS sessions (\n",
    "                    session_id TEXT PRIMARY KEY,\n",
    "                    user_id TEXT,\n",
    "                    title TEXT,\n",
    "                    status TEXT,\n",
    "                    created_at TEXT,\n",
    "                    updated_at TEXT,\n",
    "                    context TEXT,\n",
    "                    metadata TEXT\n",
    "                )\n",
    "            \"\"\")\n",
    "            \n",
    "            conn.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS messages (\n",
    "                    id TEXT PRIMARY KEY,\n",
    "                    session_id TEXT,\n",
    "                    content TEXT,\n",
    "                    message_type TEXT,\n",
    "                    timestamp TEXT,\n",
    "                    metadata TEXT,\n",
    "                    FOREIGN KEY (session_id) REFERENCES sessions (session_id)\n",
    "                )\n",
    "            \"\"\")\n",
    "    \n",
    "    def create_session(self, user_id: Optional[str] = None, \n",
    "                      title: str = \"Legal Consultation\") -> ConversationSession:\n",
    "        \"\"\"Create a new conversation session\"\"\"\n",
    "        session_id = str(uuid.uuid4())\n",
    "        now = datetime.utcnow()\n",
    "        \n",
    "        session = ConversationSession(\n",
    "            session_id=session_id,\n",
    "            user_id=user_id,\n",
    "            title=title,\n",
    "            created_at=now,\n",
    "            updated_at=now\n",
    "        )\n",
    "        \n",
    "        self.active_sessions[session_id] = session\n",
    "        logger.info(f\"Created new conversation session: {session_id}\")\n",
    "        return session\n",
    "\n",
    "class ConversationManager:\n",
    "    \"\"\"\n",
    "    High-level conversation manager that coordinates memory and context\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, db_path: str = \"conversations.db\"):\n",
    "        self.memory = ConversationMemory(db_path)\n",
    "        logger.info(\"Conversation Manager initialized\")\n",
    "    \n",
    "    def start_conversation(self, user_id: Optional[str] = None, \n",
    "                          title: str = \"Legal Consultation\") -> str:\n",
    "        \"\"\"Start a new conversation\"\"\"\n",
    "        session = self.memory.create_session(user_id, title)\n",
    "        return session.session_id\n",
    "\n",
    "print(\"Conversation Manager implementation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Legal RAG System Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoleTaggedDocument(BaseModel):\n",
    "    \"\"\"Document with role-specific metadata\"\"\"\n",
    "    content: str\n",
    "    role: str\n",
    "    doc_id: str\n",
    "    sentence_index: int\n",
    "    confidence: float\n",
    "    metadata: Dict[str, Any] = {}\n",
    "\n",
    "class LegalRAGSystem:\n",
    "    \"\"\"\n",
    "    Role-aware RAG system for legal documents\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 embedding_model: str = \"text-embedding-005\",\n",
    "                 role_classifier_type: str = \"inlegalbert\",\n",
    "                 collection_name: str = \"legal_rag\",\n",
    "                 device: str = \"cpu\"):\n",
    "        \"\"\"\n",
    "        Initialize the Legal RAG System\n",
    "        \"\"\"\n",
    "        self.device = device\n",
    "        self.collection_name = collection_name\n",
    "        \n",
    "        # Initialize role classifier\n",
    "        self.role_classifier = RoleClassifier(\n",
    "            model_type=role_classifier_type, \n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        # For demo, we'll use a simple in-memory store\n",
    "        # In production, use VertexAIEmbeddings and Chroma\n",
    "        self.docstore = InMemoryStore()\n",
    "        self.documents = []  # Simple list for demo\n",
    "        \n",
    "        logger.info(\"Legal RAG System initialized successfully\")\n",
    "    \n",
    "    def process_legal_document(self, \n",
    "                             document_text: str, \n",
    "                             doc_metadata: Dict[str, Any] = None,\n",
    "                             context_mode: str = \"prev\") -> List[RoleTaggedDocument]:\n",
    "        \"\"\"\n",
    "        Process a legal document and classify rhetorical roles\n",
    "        \"\"\"\n",
    "        if doc_metadata is None:\n",
    "            doc_metadata = {}\n",
    "        \n",
    "        # Classify rhetorical roles\n",
    "        role_results = self.role_classifier.classify_document(\n",
    "            document_text, context_mode=context_mode\n",
    "        )\n",
    "        \n",
    "        # Create role-tagged documents\n",
    "        tagged_docs = []\n",
    "        for result in role_results:\n",
    "            doc_id = str(uuid.uuid4())\n",
    "            \n",
    "            tagged_doc = RoleTaggedDocument(\n",
    "                content=result[\"sentence\"],\n",
    "                role=result[\"role\"],\n",
    "                doc_id=doc_id,\n",
    "                sentence_index=result[\"sentence_index\"],\n",
    "                confidence=result[\"confidence\"],\n",
    "                metadata={\n",
    "                    **doc_metadata,\n",
    "                    \"role\": result[\"role\"],\n",
    "                    \"sentence_index\": result[\"sentence_index\"],\n",
    "                    \"confidence\": result[\"confidence\"]\n",
    "                }\n",
    "            )\n",
    "            tagged_docs.append(tagged_doc)\n",
    "        \n",
    "        return tagged_docs\n",
    "    \n",
    "    def add_documents_to_store(self, tagged_docs: List[RoleTaggedDocument]):\n",
    "        \"\"\"Add role-tagged documents to the vector store\"\"\"\n",
    "        # For demo, just append to our list\n",
    "        self.documents.extend(tagged_docs)\n",
    "        logger.info(f\"Added {len(tagged_docs)} documents to store\")\n",
    "    \n",
    "    def retrieve_by_role(self, \n",
    "                        query: str, \n",
    "                        roles: List[str] = None, \n",
    "                        k: int = 5) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Retrieve documents filtered by specific rhetorical roles\n",
    "        \"\"\"\n",
    "        # Simple keyword matching for demo\n",
    "        query_lower = query.lower()\n",
    "        results = []\n",
    "        \n",
    "        for doc in self.documents:\n",
    "            if roles and doc.role not in roles:\n",
    "                continue\n",
    "            \n",
    "            # Simple relevance scoring\n",
    "            score = sum(1 for word in query_lower.split() if word in doc.content.lower())\n",
    "            if score > 0:\n",
    "                results.append({\n",
    "                    \"content\": doc.content,\n",
    "                    \"role\": doc.role,\n",
    "                    \"score\": score,\n",
    "                    \"metadata\": doc.metadata\n",
    "                })\n",
    "        \n",
    "        # Sort by score and return top k\n",
    "        results.sort(key=lambda x: x[\"score\"], reverse=True)\n",
    "        return results[:k]\n",
    "    \n",
    "    def query_legal_rag(self, \n",
    "                       query: str, \n",
    "                       auto_detect_roles: bool = True,\n",
    "                       specific_roles: List[str] = None,\n",
    "                       k: int = 10) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Main query interface for the legal RAG system\n",
    "        \"\"\"\n",
    "        # Determine relevant roles\n",
    "        if specific_roles:\n",
    "            search_roles = specific_roles\n",
    "        elif auto_detect_roles:\n",
    "            # Simple role detection\n",
    "            query_lower = query.lower()\n",
    "            search_roles = []\n",
    "            if \"facts\" in query_lower:\n",
    "                search_roles.append(RhetoricalRole.FACTS.value)\n",
    "            if \"decision\" in query_lower or \"judgment\" in query_lower:\n",
    "                search_roles.append(RhetoricalRole.DECISION.value)\n",
    "            if \"reasoning\" in query_lower:\n",
    "                search_roles.append(RhetoricalRole.REASONING.value)\n",
    "            \n",
    "            if not search_roles:\n",
    "                search_roles = None\n",
    "        else:\n",
    "            search_roles = None\n",
    "        \n",
    "        # Retrieve documents\n",
    "        retrieved_docs = self.retrieve_by_role(query, roles=search_roles, k=k)\n",
    "        \n",
    "        # Generate response\n",
    "        if retrieved_docs:\n",
    "            answer = \"Based on the legal documents:\\n\\n\"\n",
    "            for doc in retrieved_docs[:3]:\n",
    "                answer += f\"**{doc['role']}**: {doc['content'][:200]}...\\n\\n\"\n",
    "        else:\n",
    "            answer = \"No relevant information found in the legal documents.\"\n",
    "        \n",
    "        return {\n",
    "            \"answer\": answer,\n",
    "            \"retrieved_docs\": retrieved_docs,\n",
    "            \"search_metadata\": {\n",
    "                \"query\": query,\n",
    "                \"searched_roles\": search_roles,\n",
    "                \"retrieval_count\": len(retrieved_docs)\n",
    "            }\n",
    "        }\n",
    "\n",
    "print(\"Legal RAG System implementation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Prediction Module Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class PrecedentCase:\n",
    "    \"\"\"Precedent case information\"\"\"\n",
    "    case_id: str\n",
    "    case_name: str\n",
    "    facts: str\n",
    "    issues: str\n",
    "    reasoning: str\n",
    "    decision: str\n",
    "    outcome: JudgmentOutcome\n",
    "    case_type: CaseType\n",
    "    court: str\n",
    "    year: int\n",
    "    citation: str\n",
    "    similarity_score: float = 0.0\n",
    "\n",
    "@dataclass\n",
    "class PredictionResult:\n",
    "    \"\"\"Judgment prediction result\"\"\"\n",
    "    predicted_outcome: JudgmentOutcome\n",
    "    confidence: float\n",
    "    probability_distribution: Dict[str, float]\n",
    "    similar_cases: List[PrecedentCase]\n",
    "    key_factors: List[str]\n",
    "    reasoning: str\n",
    "    disclaimer: str\n",
    "\n",
    "class JudgmentPredictor:\n",
    "    \"\"\"\n",
    "    Main judgment prediction engine using precedent analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, rag_system: LegalRAGSystem):\n",
    "        self.rag_system = rag_system\n",
    "        \n",
    "        # Outcome patterns for extraction\n",
    "        self.outcome_patterns = {\n",
    "            JudgmentOutcome.ALLOWED: [\n",
    "                \"petition allowed\", \"appeal allowed\", \"granted\"\n",
    "            ],\n",
    "            JudgmentOutcome.DISMISSED: [\n",
    "                \"petition dismissed\", \"appeal dismissed\", \"dismissed\"\n",
    "            ],\n",
    "            JudgmentOutcome.PARTLY_ALLOWED: [\n",
    "                \"partly allowed\", \"partially allowed\"\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        logger.info(\"Judgment Predictor initialized\")\n",
    "    \n",
    "    def predict_judgment(self, case_facts: str, case_issues: str = None, \n",
    "                        case_type: CaseType = None, k_similar: int = 10) -> PredictionResult:\n",
    "        \"\"\"\n",
    "        Predict judgment outcome for a pending case\n",
    "        \"\"\"\n",
    "        # Prepare case text for analysis\n",
    "        case_text = case_facts\n",
    "        if case_issues:\n",
    "            case_text += f\" Issues: {case_issues}\"\n",
    "        \n",
    "        # For demo, create a simple prediction\n",
    "        # In production, this would use similarity analysis and ML models\n",
    "        \n",
    "        # Analyze text for outcome indicators\n",
    "        case_lower = case_text.lower()\n",
    "        \n",
    "        if \"fundamental rights\" in case_lower or \"violation\" in case_lower:\n",
    "            predicted_outcome = JudgmentOutcome.ALLOWED\n",
    "            confidence = 0.70\n",
    "            probabilities = {\n",
    "                \"allowed\": 0.70,\n",
    "                \"dismissed\": 0.20,\n",
    "                \"partly_allowed\": 0.10\n",
    "            }\n",
    "        else:\n",
    "            predicted_outcome = JudgmentOutcome.DISMISSED\n",
    "            confidence = 0.60\n",
    "            probabilities = {\n",
    "                \"allowed\": 0.25,\n",
    "                \"dismissed\": 0.60,\n",
    "                \"partly_allowed\": 0.15\n",
    "            }\n",
    "        \n",
    "        # Extract key factors\n",
    "        key_factors = []\n",
    "        if \"constitutional\" in case_lower:\n",
    "            key_factors.append(\"Constitutional validity question\")\n",
    "        if \"fundamental rights\" in case_lower:\n",
    "            key_factors.append(\"Fundamental rights violation claim\")\n",
    "        if \"procedure\" in case_lower:\n",
    "            key_factors.append(\"Procedural irregularity\")\n",
    "        \n",
    "        # Create demo similar cases\n",
    "        similar_cases = [\n",
    "            PrecedentCase(\n",
    "                case_id=\"case_001\",\n",
    "                case_name=\"Similar Case v. State\",\n",
    "                facts=\"Similar facts involving fundamental rights\",\n",
    "                issues=\"Constitutional validity\",\n",
    "                reasoning=\"Court found violation\",\n",
    "                decision=\"Petition allowed\",\n",
    "                outcome=JudgmentOutcome.ALLOWED,\n",
    "                case_type=CaseType.CONSTITUTIONAL,\n",
    "                court=\"Supreme Court\",\n",
    "                year=2022,\n",
    "                citation=\"2022 SCC 123\",\n",
    "                similarity_score=0.85\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        reasoning = f\"\"\"\n",
    "        Based on analysis of similar precedent cases:\n",
    "        1. The case involves {', '.join(key_factors) if key_factors else 'standard legal issues'}\n",
    "        2. Similar cases with these characteristics have historically resulted in {predicted_outcome.value}\n",
    "        3. The confidence level is {confidence:.1%} based on precedent analysis\n",
    "        \"\"\"\n",
    "        \n",
    "        disclaimer = \"\"\"\n",
    "        **LEGAL DISCLAIMER**: This prediction is for informational purposes only \n",
    "        and should not be considered as legal advice. Actual court decisions depend on \n",
    "        numerous factors and should be evaluated by qualified legal counsel.\n",
    "        \"\"\"\n",
    "        \n",
    "        return PredictionResult(\n",
    "            predicted_outcome=predicted_outcome,\n",
    "            confidence=confidence,\n",
    "            probability_distribution=probabilities,\n",
    "            similar_cases=similar_cases,\n",
    "            key_factors=key_factors,\n",
    "            reasoning=reasoning,\n",
    "            disclaimer=disclaimer\n",
    "        )\n",
    "\n",
    "print(\"Prediction Module implementation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Agent Orchestrator Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class QueryClassification:\n",
    "    \"\"\"Classification result for user query\"\"\"\n",
    "    query_type: QueryType\n",
    "    intent: Intent\n",
    "    relevant_roles: List[str]\n",
    "    confidence: float\n",
    "    requires_context: bool\n",
    "    suggested_tools: List[str]\n",
    "    metadata: Dict[str, Any]\n",
    "\n",
    "class QueryRouter:\n",
    "    \"\"\"\n",
    "    Intelligent query routing based on content analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.role_keywords = {\n",
    "            RhetoricalRole.FACTS.value: [\n",
    "                \"facts\", \"background\", \"what happened\", \"events\"\n",
    "            ],\n",
    "            RhetoricalRole.DECISION.value: [\n",
    "                \"decision\", \"judgment\", \"ruling\", \"verdict\"\n",
    "            ],\n",
    "            RhetoricalRole.REASONING.value: [\n",
    "                \"reasoning\", \"rationale\", \"why\", \"analysis\"\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    def classify_query(self, query: str, context: Dict[str, Any] = None) -> QueryClassification:\n",
    "        \"\"\"Classify user query to determine routing strategy\"\"\"\n",
    "        query_lower = query.lower()\n",
    "        context = context or {}\n",
    "        \n",
    "        # Detect query type\n",
    "        if \"predict\" in query_lower or \"outcome\" in query_lower:\n",
    "            query_type = QueryType.PREDICTION_REQUEST\n",
    "        elif \"summary\" in query_lower or \"summarize\" in query_lower:\n",
    "            query_type = QueryType.CASE_SUMMARY\n",
    "        elif \"facts\" in query_lower or \"reasoning\" in query_lower:\n",
    "            query_type = QueryType.ROLE_SPECIFIC_QUERY\n",
    "        else:\n",
    "            query_type = QueryType.LEGAL_RESEARCH\n",
    "        \n",
    "        # Detect intent\n",
    "        if \"find\" in query_lower or \"search\" in query_lower:\n",
    "            intent = Intent.SEARCH\n",
    "        elif \"explain\" in query_lower or \"what\" in query_lower:\n",
    "            intent = Intent.EXPLAIN\n",
    "        elif \"predict\" in query_lower:\n",
    "            intent = Intent.PREDICT\n",
    "        else:\n",
    "            intent = Intent.CLARIFY\n",
    "        \n",
    "        # Detect relevant roles\n",
    "        relevant_roles = []\n",
    "        for role, keywords in self.role_keywords.items():\n",
    "            if any(keyword in query_lower for keyword in keywords):\n",
    "                relevant_roles.append(role)\n",
    "        \n",
    "        return QueryClassification(\n",
    "            query_type=query_type,\n",
    "            intent=intent,\n",
    "            relevant_roles=relevant_roles,\n",
    "            confidence=0.8,\n",
    "            requires_context=False,\n",
    "            suggested_tools=[\"rag\", \"classifier\"],\n",
    "            metadata={\"query_length\": len(query)}\n",
    "        )\n",
    "\n",
    "class AgentOrchestrator:\n",
    "    \"\"\"\n",
    "    Main orchestrator that coordinates all components\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, db_path: str = \"legal_system.db\", device: str = \"cpu\"):\n",
    "        self.device = device\n",
    "        \n",
    "        # Initialize components\n",
    "        self.query_router = QueryRouter()\n",
    "        self.conversation_manager = ConversationManager(db_path)\n",
    "        self.document_processor = LegalDocumentProcessor()\n",
    "        self.rag_system = LegalRAGSystem(device=device)\n",
    "        self.prediction_module = JudgmentPredictor(self.rag_system)\n",
    "        \n",
    "        logger.info(\"Agent Orchestrator initialized successfully\")\n",
    "    \n",
    "    def process_query(self, query: str, session_id: str = None, \n",
    "                     context: Dict[str, Any] = None) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Main query processing function\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Get or create session\n",
    "            if not session_id:\n",
    "                session_id = self.conversation_manager.start_conversation()\n",
    "            \n",
    "            # Classify the query\n",
    "            classification = self.query_router.classify_query(query, context)\n",
    "            \n",
    "            # Route to appropriate handler\n",
    "            if classification.query_type == QueryType.PREDICTION_REQUEST:\n",
    "                # Handle prediction request\n",
    "                result = self.prediction_module.predict_judgment(query)\n",
    "                answer = f\"\"\"\n",
    "                **Predicted Outcome**: {result.predicted_outcome.value}\n",
    "                **Confidence**: {result.confidence:.1%}\n",
    "                \n",
    "                {result.reasoning}\n",
    "                \n",
    "                {result.disclaimer}\n",
    "                \"\"\"\n",
    "            elif classification.query_type == QueryType.ROLE_SPECIFIC_QUERY:\n",
    "                # Handle role-specific query\n",
    "                rag_response = self.rag_system.query_legal_rag(\n",
    "                    query,\n",
    "                    specific_roles=classification.relevant_roles\n",
    "                )\n",
    "                answer = rag_response[\"answer\"]\n",
    "            else:\n",
    "                # Default handling\n",
    "                rag_response = self.rag_system.query_legal_rag(query)\n",
    "                answer = rag_response[\"answer\"]\n",
    "            \n",
    "            return {\n",
    "                \"answer\": answer,\n",
    "                \"session_id\": session_id,\n",
    "                \"classification\": asdict(classification),\n",
    "                \"tools_used\": classification.suggested_tools\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing query: {e}\")\n",
    "            return {\n",
    "                \"answer\": \"I apologize, but I encountered an error. Please try again.\",\n",
    "                \"error\": str(e),\n",
    "                \"session_id\": session_id\n",
    "            }\n",
    "\n",
    "print(\"Agent Orchestrator implementation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. System Integration and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the complete system\n",
    "print(\"Initializing Legal Document Analysis System...\")\n",
    "orchestrator = AgentOrchestrator()\n",
    "print(\"System initialized successfully!\\n\")\n",
    "\n",
    "# Sample legal document for testing\n",
    "sample_case_text = \"\"\"\n",
    "Ram Kumar v. State of Maharashtra\n",
    "\n",
    "Supreme Court of India\n",
    "Civil Appeal No. 123/2023\n",
    "\n",
    "FACTS:\n",
    "The petitioner filed a writ petition challenging the constitutional validity of Section 377.\n",
    "The petitioner was arrested without warrant on charges of theft.\n",
    "\n",
    "ISSUES:\n",
    "The main issue is whether Section 377 violates fundamental rights.\n",
    "Whether the arrest without warrant was constitutional?\n",
    "\n",
    "ARGUMENTS OF PETITIONER:\n",
    "The petitioner argues that Section 377 is discriminatory and violates Article 14.\n",
    "The arrest violated due process under Article 21.\n",
    "\n",
    "ARGUMENTS OF RESPONDENT:\n",
    "The respondent contends that Section 377 is constitutionally valid.\n",
    "The arrest was lawful under the applicable law.\n",
    "\n",
    "REASONING:\n",
    "The court finds that Section 377 infringes upon the right to privacy and equality.\n",
    "The court analyzed the constitutional provisions and precedents.\n",
    "\n",
    "DECISION:\n",
    "Therefore, Section 377 is hereby declared unconstitutional.\n",
    "The petition is allowed and the arrest is quashed.\n",
    "\"\"\"\n",
    "\n",
    "# Process the sample document\n",
    "print(\"Processing sample legal document...\")\n",
    "tagged_docs = orchestrator.rag_system.process_legal_document(sample_case_text)\n",
    "orchestrator.rag_system.add_documents_to_store(tagged_docs)\n",
    "print(f\"Document processed: {len(tagged_docs)} sentences classified\\n\")\n",
    "\n",
    "# Display role classification results\n",
    "print(\"Role Classification Results:\")\n",
    "role_counts = {}\n",
    "for doc in tagged_docs[:5]:  # Show first 5\n",
    "    print(f\"- {doc.role}: {doc.content[:60]}...\")\n",
    "    role_counts[doc.role] = role_counts.get(doc.role, 0) + 1\n",
    "\n",
    "print(f\"\\nRole Distribution: {role_counts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Interactive Query Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_query_interface(orchestrator):\n",
    "    \"\"\"\n",
    "    Interactive interface for testing queries\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Legal Document Analysis System - Interactive Query Interface\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\nSample queries you can try:\")\n",
    "    print(\"1. What are the facts of the case?\")\n",
    "    print(\"2. What was the court's decision?\")\n",
    "    print(\"3. Explain the reasoning behind the judgment\")\n",
    "    print(\"4. Predict the outcome if I file a similar petition\")\n",
    "    print(\"5. Summarize the case\")\n",
    "    print(\"\\nType 'exit' to quit\\n\")\n",
    "    \n",
    "    session_id = orchestrator.conversation_manager.start_conversation()\n",
    "    print(f\"Session started: {session_id}\\n\")\n",
    "    \n",
    "    while True:\n",
    "        query = input(\"\\nYour query: \")\n",
    "        if query.lower() == 'exit':\n",
    "            print(\"\\nThank you for using the Legal Document Analysis System!\")\n",
    "            break\n",
    "        \n",
    "        print(\"\\nProcessing...\")\n",
    "        response = orchestrator.process_query(query, session_id)\n",
    "        \n",
    "        print(\"\\n\" + \"-\"*60)\n",
    "        print(\"**Response:**\")\n",
    "        print(response[\"answer\"])\n",
    "        \n",
    "        if \"classification\" in response:\n",
    "            print(f\"\\n**Query Type:** {response['classification']['query_type']}\")\n",
    "            print(f\"**Tools Used:** {', '.join(response.get('tools_used', []))}\")\n",
    "        print(\"-\"*60)\n",
    "\n",
    "# Uncomment to run interactive interface\n",
    "# interactive_query_interface(orchestrator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Batch Query Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with multiple queries\n",
    "test_queries = [\n",
    "    \"What are the facts of the case?\",\n",
    "    \"What was the court's decision?\",\n",
    "    \"Explain the constitutional issues involved\",\n",
    "    \"What were the petitioner's arguments?\",\n",
    "    \"Predict the outcome if someone files a similar case\"\n",
    "]\n",
    "\n",
    "print(\"Testing Multiple Queries:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "session_id = orchestrator.conversation_manager.start_conversation()\n",
    "\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    print(f\"\\nQuery {i}: {query}\")\n",
    "    print(\"-\"*40)\n",
    "    \n",
    "    response = orchestrator.process_query(query, session_id)\n",
    "    \n",
    "    # Display truncated response\n",
    "    answer = response[\"answer\"]\n",
    "    if len(answer) > 200:\n",
    "        answer = answer[:200] + \"...\"\n",
    "    \n",
    "    print(f\"Response: {answer}\")\n",
    "    print(f\"Query Type: {response['classification']['query_type']}\")\n",
    "    print(f\"Relevant Roles: {response['classification']['relevant_roles']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Testing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Performance Metrics and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def evaluate_system_performance(orchestrator, test_queries):\n",
    "    \"\"\"\n",
    "    Evaluate system performance metrics\n",
    "    \"\"\"\n",
    "    print(\"System Performance Evaluation\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    metrics = {\n",
    "        \"query_times\": [],\n",
    "        \"query_types\": {},\n",
    "        \"roles_detected\": {},\n",
    "        \"confidence_scores\": []\n",
    "    }\n",
    "    \n",
    "    session_id = orchestrator.conversation_manager.start_conversation()\n",
    "    \n",
    "    for query in test_queries:\n",
    "        start_time = time.time()\n",
    "        response = orchestrator.process_query(query, session_id)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        # Collect metrics\n",
    "        query_time = end_time - start_time\n",
    "        metrics[\"query_times\"].append(query_time)\n",
    "        \n",
    "        classification = response[\"classification\"]\n",
    "        query_type = classification[\"query_type\"]\n",
    "        metrics[\"query_types\"][query_type] = metrics[\"query_types\"].get(query_type, 0) + 1\n",
    "        \n",
    "        for role in classification[\"relevant_roles\"]:\n",
    "            metrics[\"roles_detected\"][role] = metrics[\"roles_detected\"].get(role, 0) + 1\n",
    "        \n",
    "        metrics[\"confidence_scores\"].append(classification[\"confidence\"])\n",
    "    \n",
    "    # Calculate statistics\n",
    "    avg_time = np.mean(metrics[\"query_times\"])\n",
    "    max_time = np.max(metrics[\"query_times\"])\n",
    "    min_time = np.min(metrics[\"query_times\"])\n",
    "    avg_confidence = np.mean(metrics[\"confidence_scores\"])\n",
    "    \n",
    "    print(f\"\\nPerformance Metrics:\")\n",
    "    print(f\"- Average Query Time: {avg_time:.3f} seconds\")\n",
    "    print(f\"- Min/Max Query Time: {min_time:.3f}s / {max_time:.3f}s\")\n",
    "    print(f\"- Average Confidence: {avg_confidence:.2%}\")\n",
    "    \n",
    "    print(f\"\\nQuery Type Distribution:\")\n",
    "    for qtype, count in metrics[\"query_types\"].items():\n",
    "        print(f\"- {qtype}: {count}\")\n",
    "    \n",
    "    print(f\"\\nRoles Detected:\")\n",
    "    for role, count in metrics[\"roles_detected\"].items():\n",
    "        print(f\"- {role}: {count}\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Evaluate performance\n",
    "metrics = evaluate_system_performance(orchestrator, test_queries)\n",
    "print(\"\\nEvaluation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Visualization of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_role_distribution(tagged_docs):\n",
    "    \"\"\"\n",
    "    Visualize the distribution of rhetorical roles\n",
    "    \"\"\"\n",
    "    role_counts = {}\n",
    "    for doc in tagged_docs:\n",
    "        role_counts[doc.role] = role_counts.get(doc.role, 0) + 1\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(role_counts.keys(), role_counts.values(), color='steelblue')\n",
    "    plt.xlabel('Rhetorical Role')\n",
    "    plt.ylabel('Number of Sentences')\n",
    "    plt.title('Distribution of Rhetorical Roles in Legal Document')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return role_counts\n",
    "\n",
    "# Visualize role distribution\n",
    "role_distribution = visualize_role_distribution(tagged_docs)\n",
    "print(f\"\\nRole Distribution Summary:\")\n",
    "for role, count in role_distribution.items():\n",
    "    percentage = (count / len(tagged_docs)) * 100\n",
    "    print(f\"- {role}: {count} sentences ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Export System State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_system_state(orchestrator, filename=\"system_state.json\"):\n",
    "    \"\"\"\n",
    "    Export current system state for persistence\n",
    "    \"\"\"\n",
    "    state = {\n",
    "        \"timestamp\": datetime.utcnow().isoformat(),\n",
    "        \"documents_count\": len(orchestrator.rag_system.documents),\n",
    "        \"active_sessions\": len(orchestrator.conversation_manager.memory.active_sessions),\n",
    "        \"role_distribution\": {},\n",
    "        \"system_config\": {\n",
    "            \"device\": orchestrator.device,\n",
    "            \"collection_name\": orchestrator.rag_system.collection_name\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Calculate role distribution\n",
    "    for doc in orchestrator.rag_system.documents:\n",
    "        role = doc.role\n",
    "        state[\"role_distribution\"][role] = state[\"role_distribution\"].get(role, 0) + 1\n",
    "    \n",
    "    # Save to file\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(state, f, indent=2)\n",
    "    \n",
    "    print(f\"System state exported to {filename}\")\n",
    "    return state\n",
    "\n",
    "# Export system state\n",
    "system_state = export_system_state(orchestrator)\n",
    "print(f\"\\nSystem State Summary:\")\n",
    "print(f\"- Documents in store: {system_state['documents_count']}\")\n",
    "print(f\"- Active sessions: {system_state['active_sessions']}\")\n",
    "print(f\"- Timestamp: {system_state['timestamp']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Conclusion and Next Steps\n",
    "\n",
    "This notebook demonstrates a complete implementation of the **Intelligent Agent for Legal Document Analysis** system with:\n",
    "\n",
    "###  Implemented Components:\n",
    "1. **Role Classifier** - Segments documents into rhetorical roles\n",
    "2. **Document Processor** - Extracts and cleans legal documents\n",
    "3. **Legal RAG System** - Role-aware retrieval and generation\n",
    "4. **Conversation Manager** - Multi-turn dialogue support\n",
    "5. **Prediction Module** - Judgment outcome prediction\n",
    "6. **Agent Orchestrator** - Intelligent query routing\n",
    "\n",
    "###  Next Steps for Production:\n",
    "\n",
    "1. **Model Training**:\n",
    "   - Train InLegalBERT on Indian legal corpus\n",
    "   - Fine-tune LLMs for legal domain\n",
    "\n",
    "2. **Database Integration**:\n",
    "   - Replace in-memory stores with production databases\n",
    "   - Implement vector databases (Pinecone/FAISS)\n",
    "\n",
    "3. **API Deployment**:\n",
    "   - Containerize with Docker\n",
    "   - Deploy with Kubernetes\n",
    "   - Add authentication and rate limiting\n",
    "\n",
    "4. **Performance Optimization**:\n",
    "   - GPU acceleration for models\n",
    "   - Caching for frequent queries\n",
    "   - Batch processing for documents\n",
    "\n",
    "5. **Evaluation**:\n",
    "   - Benchmark on legal datasets\n",
    "   - A/B testing with legal professionals\n",
    "   - Continuous monitoring and improvement\n",
    "\n",
    "###  Resources:\n",
    "- [NyayaAnumana Dataset](https://aclanthology.org/2025.coling-main.738/)\n",
    "- [InLegalBERT Model](https://arxiv.org/abs/2209.06049)\n",
    "- [LangChain Documentation](https://python.langchain.com/)\n",
    "\n",
    "---\n",
    "\n",
    "**Thank you for using the Legal Document Analysis System!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
